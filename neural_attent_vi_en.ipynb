{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import unicode_literals, print_function, division\n",
    "from io import open\n",
    "import unicodedata\n",
    "import string\n",
    "import re\n",
    "import random\n",
    "import numpy as np\n",
    "import pdb\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import io\n",
    "import os\n",
    "import sacrebleu\n",
    "import math\n",
    "\n",
    "from torch.autograd import Variable\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "PAD_idx = 0\n",
    "SOS_idx = 1\n",
    "EOS_idx = 2\n",
    "UNK_idx= 3\n",
    "batch_size = 64\n",
    "MAX_SENTENCE_LENGTH = 40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "en_pretrained_path = './wiki-news-300d-1M.vec'\n",
    "zh_pretrained_path = './cc.vi.300.vec'\n",
    "data_prefix = './'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Rachel Pike : The science behind a climate headline',\n",
       " 'In 4 minutes , atmospheric chemist Rachel Pike provides a glimpse of the massive scientific effort behind the bold headlines on climate change , with her team -- one of thousands who contributed -- taking a risky flight over the rainforest in pursuit of data on a key molecule .',\n",
       " 'I &apos;d like to talk to you today about the scale of the scientific effort that goes into making the headlines you see in the paper .',\n",
       " 'Headlines that look like this when they have to do with climate change , and headlines that look like this when they have to do with air quality or smog .',\n",
       " 'They are both two branches of the same field of atmospheric science .',\n",
       " 'Recently the headlines looked like this when the Intergovernmental Panel on Climate Change , or IPCC , put out their report on the state of understanding of the atmospheric system .',\n",
       " 'That report was written by 620 scientists from 40 countries .',\n",
       " 'They wrote almost a thousand pages on the topic .',\n",
       " 'And all of those pages were reviewed by another 400-plus scientists and reviewers , from 113 countries .',\n",
       " 'It &apos;s a big community . It &apos;s such a big community , in fact , that our annual gathering is the largest scientific meeting in the world .']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "['Rachel Pike : The science behind a climate headline',\n",
       " 'In 4 minutes , atmospheric chemist Rachel Pike provides a glimpse of the massive scientific effort behind the bold headlines on climate change , with her team -- one of thousands who contributed -- taking a risky flight over the rainforest in pursuit of data on a key molecule .',\n",
       " 'I &apos;d like to talk to you today about the scale of the scientific effort that goes into making the headlines you see in the paper .',\n",
       " 'Headlines that look like this when they have to do with climate change , and headlines that look like this when they have to do with air quality or smog .',\n",
       " 'They are both two branches of the same field of atmospheric science .',\n",
       " 'Recently the headlines looked like this when the Intergovernmental Panel on Climate Change , or IPCC , put out their report on the state of understanding of the atmospheric system .',\n",
       " 'That report was written by 620 scientists from 40 countries .',\n",
       " 'They wrote almost a thousand pages on the topic .',\n",
       " 'And all of those pages were reviewed by another 400-plus scientists and reviewers , from 113 countries .',\n",
       " 'It &apos;s a big community . It &apos;s such a big community , in fact , that our annual gathering is the largest scientific meeting in the world .']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_en = open('iwslt-vi-en/train.tok.en' , encoding='utf-8').read().strip().split('\\n')\n",
    "val_en = open('iwslt-vi-en/dev.tok.en', encoding='utf-8').read().strip().split('\\n')\n",
    "test_en = open('iwslt-vi-en/test.tok.en', encoding='utf-8').read().strip().split('\\n')\n",
    "train_en[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Khoa_học đằng_sau một tiêu_đề về khí_hậu',\n",
       " 'Trong 4 phút , chuyên_gia hoá_học khí_quyển Rachel Pike giới_thiệu sơ_lược về những nỗ_lực khoa_học miệt_mài đằng_sau những tiêu_đề táo_bạo về biến_đổi khí_hậu , cùng với đoàn nghiên_cứu của mình - - hàng ngàn người đã cống_hiến cho dự_án này - - một chuyến bay mạo_hiểm qua rừng_già để tìm_kiếm thông_tin về một phân_tử then_chốt .',\n",
       " 'Tôi muốn cho các bạn biết về sự to_lớn của những nỗ_lực khoa_học đã góp_phần làm_nên các dòng tít bạn thường thấy trên báo .',\n",
       " 'Có những dòng trông như thế_này khi bàn về biến_đổi khí_hậu , và như thế_này khi nói về chất_lượng không_khí hay khói bụi .',\n",
       " 'Cả hai đều là một nhánh của cùng một lĩnh_vực trong ngành khoa_học khí_quyển .',\n",
       " 'Các tiêu_đề gần_đây trông như thế_này khi Ban Điều_hành Biến_đổi khí_hậu Liên_chính_phủ , gọi tắt là IPCC đưa ra_bài nghiên_cứu của họ về hệ_thống khí_quyển .',\n",
       " 'Nghiên_cứu được viết bởi 620 nhà khoa_học từ 40 quốc_gia khác nhau .',\n",
       " 'Họ viết gần 1000 trang về chủ_đề này .',\n",
       " 'Và tất_cả các trang đều được xem_xét bởi 400 khoa_học gia và nhà phê_bình khác từ 113 quốc_gia .',\n",
       " 'Đó là cả một cộng_đồng lớn , lớn đến_nỗi trên thực_tế cuộc tụ_hội hằng năm của chúng_tôi là hội_nghị khoa_học [ tự_nhiên ] lớn nhất thế_giới .']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "['Khoa_học đằng_sau một tiêu_đề về khí_hậu',\n",
       " 'Trong 4 phút , chuyên_gia hoá_học khí_quyển Rachel Pike giới_thiệu sơ_lược về những nỗ_lực khoa_học miệt_mài đằng_sau những tiêu_đề táo_bạo về biến_đổi khí_hậu , cùng với đoàn nghiên_cứu của mình - - hàng ngàn người đã cống_hiến cho dự_án này - - một chuyến bay mạo_hiểm qua rừng_già để tìm_kiếm thông_tin về một phân_tử then_chốt .',\n",
       " 'Tôi muốn cho các bạn biết về sự to_lớn của những nỗ_lực khoa_học đã góp_phần làm_nên các dòng tít bạn thường thấy trên báo .',\n",
       " 'Có những dòng trông như thế_này khi bàn về biến_đổi khí_hậu , và như thế_này khi nói về chất_lượng không_khí hay khói bụi .',\n",
       " 'Cả hai đều là một nhánh của cùng một lĩnh_vực trong ngành khoa_học khí_quyển .',\n",
       " 'Các tiêu_đề gần_đây trông như thế_này khi Ban Điều_hành Biến_đổi khí_hậu Liên_chính_phủ , gọi tắt là IPCC đưa ra_bài nghiên_cứu của họ về hệ_thống khí_quyển .',\n",
       " 'Nghiên_cứu được viết bởi 620 nhà khoa_học từ 40 quốc_gia khác nhau .',\n",
       " 'Họ viết gần 1000 trang về chủ_đề này .',\n",
       " 'Và tất_cả các trang đều được xem_xét bởi 400 khoa_học gia và nhà phê_bình khác từ 113 quốc_gia .',\n",
       " 'Đó là cả một cộng_đồng lớn , lớn đến_nỗi trên thực_tế cuộc tụ_hội hằng năm của chúng_tôi là hội_nghị khoa_học [ tự_nhiên ] lớn nhất thế_giới .']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_zh = open('iwslt-vi-en/train.tok.vi', encoding='utf-8').read().strip().split('\\n')\n",
    "val_zh = open('iwslt-vi-en/dev.tok.vi', encoding='utf-8').read().strip().split('\\n')\n",
    "test_zh = open('iwslt-vi-en/test.tok.vi', encoding='utf-8').read().strip().split('\\n')\n",
    "\n",
    "train_zh[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of train data: 133317\n",
      "Length of val data: 1268\n",
      "Length of test data: 1553\n",
      "Length of train data: 133317\n",
      "Length of val data: 1268\n",
      "Length of test data: 1553\n"
     ]
    }
   ],
   "source": [
    "print ('Length of train data:', len(train_en))\n",
    "print ('Length of val data:', len(val_en))\n",
    "print ('Length of test data:', len(test_en))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_dataframe(en, ch, len_raio=0.8):\n",
    "    en_len_list, ch_len_list = [], []\n",
    "    for en_sample, ch_sample in zip(en, ch):\n",
    "        en_len_list.append(len(en_sample))\n",
    "        ch_len_list.append(len(ch_sample))\n",
    "    df = pd.DataFrame({'en': en, \n",
    "                       'en_len': en_len_list,\n",
    "                       'ch': ch,\n",
    "                       'ch_len': ch_len_list\n",
    "                      })\n",
    "    en_len_at_ratio = sorted(en_len_list)[int(len_raio*len(en_len_list))]\n",
    "    ch_len_at_ratio = sorted(ch_len_list)[int(len_raio*len(ch_len_list))]\n",
    "    print (\"EN length @{}: {}, CH length @{}: {}\".format(len_raio, en_len_at_ratio, len_raio, ch_len_at_ratio))\n",
    "    return df, max(en_len_at_ratio, ch_len_at_ratio)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "load pre-trained embedding and create the index2words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the vocabulary based on the training data\n",
    "from collections import Counter\n",
    "\n",
    "def get_vocabulary(data, VOCABULARY_SIZE=10000):\n",
    "    en_vocab, ch_vocab = [], []\n",
    "    for idx, row in data.iterrows():\n",
    "        en_vocab += row['en'].split()\n",
    "        ch_vocab += row['ch'].split()\n",
    "    en_token_counter = Counter(en_vocab)\n",
    "    ch_token_counter = Counter(ch_vocab)\n",
    "    print (\"Number of en words: {}, ch words: {}\".format(len(en_token_counter), len(ch_token_counter)))\n",
    "    en_word, _ = zip(*en_token_counter.most_common(VOCABULARY_SIZE))\n",
    "    en_id2token = ['<PAD>','<SOS>','<EOS>','<UNK>'] + list(en_word)\n",
    "    en_token2id = dict(zip(en_id2token, np.arange(len(en_id2token))))\n",
    "    ch_word, _ = zip(*ch_token_counter.most_common(VOCABULARY_SIZE))\n",
    "    ch_id2token = ['<PAD>','<SOS>','<EOS>','<UNK>'] + list(ch_word)\n",
    "    ch_token2id = dict(zip(ch_id2token, np.arange(len(ch_id2token))))\n",
    "    return en_id2token, en_token2id, ch_id2token, ch_token2id\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_vectors(fname):\n",
    "    \"\"\"\n",
    "    load the pretrained word embeddings\n",
    "    param fname: the path the to the word embedding\n",
    "    return: \n",
    "            a dictionary of the {word: embedding}\n",
    "    \"\"\"\n",
    "    fin = io.open(fname, 'r', encoding='utf-8', newline='\\n', errors='ignore')\n",
    "    n, d = map(int, fin.readline().split())\n",
    "    data = {}\n",
    "    for line in tqdm(fin):\n",
    "        tokens = line.rstrip().split(' ')\n",
    "        data[tokens[0]] = list(map(float, tokens[1:]))\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_pickle(data_path, callback, *callback_args):\n",
    "    \"\"\"\n",
    "    Create huge file with the callback function if not exist, otherwise load directly\n",
    "    param data_path: the path of the load file if exist, otherwise the path to store the created file\n",
    "    param callback: the function to generate the data if not exist\n",
    "    param callback_args: the argument for the callback:\n",
    "    return: \n",
    "            the data, either loaded or created by callback\n",
    "    \"\"\"\n",
    "\n",
    "    data_path = data_prefix+data_path\n",
    "    if os.path.isfile(data_path):\n",
    "        print ('File exists, load from path...')\n",
    "        data = pickle.load(open(data_path, 'rb'))\n",
    "    else:\n",
    "        print ('File not exists, creating...')\n",
    "        data = callback(*callback_args)\n",
    "        pickle.dump(data, open(data_path, 'wb'))\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embedding_weights(whole_vec, id2token):\n",
    "    \"\"\"\n",
    "    get the embeddings based on the word, create the embedding matrix\n",
    "    param whole_vec: the dictionary of pretrained embeddings\n",
    "    param id2token: the whole vocabulary\n",
    "    return:\n",
    "            embedding matrix\n",
    "    \"\"\"\n",
    "    weight = np.zeros((len(id2token), len(whole_vec['sky'])))\n",
    "    mask = np.zeros((len(id2token)))\n",
    "    for i, word in enumerate(id2token[1:]):\n",
    "        if word in whole_vec.keys():\n",
    "            weight[i+1] = np.array(whole_vec[word])\n",
    "        else:\n",
    "            weight[i+1] = np.array(whole_vec['UNK'])\n",
    "            mask[i+1] = 1\n",
    "            print (\"Out of vocabulary word: \", word)   \n",
    "    return weight, mask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalize english sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Turn a Unicode string to plain ASCII\n",
    "def unicodeToAscii(s):\n",
    "    return ''.join(\n",
    "        c for c in unicodedata.normalize('NFD', s)\n",
    "        if unicodedata.category(c) != 'Mn')\n",
    "\n",
    "# Lowercase, trim, and remove non-letter characters\n",
    "def normalizeString(s):\n",
    "    s = unicodeToAscii(s.lower().strip())\n",
    "    s = re.sub(r\"([.!?])\", r\" \\1\", s)\n",
    "    #s = re.sub(r\"[^a-zA-Z.!?]+\", r\" \", s)\n",
    "    s = re.sub(r\"[^a-zA-Z]+\", r\" \", s)\n",
    "    s = s.strip()\n",
    "    return s\n",
    "\n",
    "def normalizeZh(s):\n",
    "    #s = s.decode(\"utf8\")\n",
    "    #s = re.sub(\"[\\s+\\.\\!\\/_,$%^*(+\\\"\\']+|[+——！，。？、~@#￥%……&*（）％]+\", \" \",s)\n",
    "    s = re.sub( '\\s+', ' ', s )\n",
    "    s = s.strip()\n",
    "    return s\n",
    "\n",
    "def normalizeVi(s):\n",
    "    s = s.lower().strip()\n",
    "    s =re.sub(r\"[-()\\\"#/@;:<>{}`+=~|,]\", \"\", s)\n",
    "    s = re.sub(r\"[0-9]\",\"\",s)\n",
    "    s = re.sub( '\\s+', ' ', s)\n",
    "    return s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Token to index function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def token_to_index(sentence, token2id):\n",
    "    indicies_data = []\n",
    "    for s in sentence:\n",
    "        tokens = s.split(' ')\n",
    "        index_list =[token2id[token] if token in token2id else UNK_idx for token in tokens]\n",
    "        assert len(tokens) == len(index_list)\n",
    "        indicies_data.append(index_list)\n",
    "    return indicies_data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** English**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalize_train_en = [normalizeString(s) for s in train_en]\n",
    "normalize_val_en = [normalizeString(s) for s in val_en]\n",
    "normalize_test_en = [normalizeString(s) for s in test_en]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['rachel pike the science behind a climate headline',\n",
       " 'in minutes atmospheric chemist rachel pike provides a glimpse of the massive scientific effort behind the bold headlines on climate change with her team one of thousands who contributed taking a risky flight over the rainforest in pursuit of data on a key molecule',\n",
       " 'i apos d like to talk to you today about the scale of the scientific effort that goes into making the headlines you see in the paper',\n",
       " 'headlines that look like this when they have to do with climate change and headlines that look like this when they have to do with air quality or smog',\n",
       " 'they are both two branches of the same field of atmospheric science',\n",
       " 'recently the headlines looked like this when the intergovernmental panel on climate change or ipcc put out their report on the state of understanding of the atmospheric system',\n",
       " 'that report was written by scientists from countries',\n",
       " 'they wrote almost a thousand pages on the topic',\n",
       " 'and all of those pages were reviewed by another plus scientists and reviewers from countries',\n",
       " 'it apos s a big community it apos s such a big community in fact that our annual gathering is the largest scientific meeting in the world']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "['rachel pike the science behind a climate headline',\n",
       " 'in minutes atmospheric chemist rachel pike provides a glimpse of the massive scientific effort behind the bold headlines on climate change with her team one of thousands who contributed taking a risky flight over the rainforest in pursuit of data on a key molecule',\n",
       " 'i apos d like to talk to you today about the scale of the scientific effort that goes into making the headlines you see in the paper',\n",
       " 'headlines that look like this when they have to do with climate change and headlines that look like this when they have to do with air quality or smog',\n",
       " 'they are both two branches of the same field of atmospheric science',\n",
       " 'recently the headlines looked like this when the intergovernmental panel on climate change or ipcc put out their report on the state of understanding of the atmospheric system',\n",
       " 'that report was written by scientists from countries',\n",
       " 'they wrote almost a thousand pages on the topic',\n",
       " 'and all of those pages were reviewed by another plus scientists and reviewers from countries',\n",
       " 'it apos s a big community it apos s such a big community in fact that our annual gathering is the largest scientific meeting in the world']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normalize_train_en[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Vinamese**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalize_train_zh = [normalizeVi(s) for s in train_zh]\n",
    "normalize_val_zh = [normalizeVi(s) for s in val_zh]\n",
    "normalize_test_zh = [normalizeVi(s) for s in test_zh]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['khoa_học đằng_sau một tiêu_đề về khí_hậu',\n",
       " 'trong phút chuyên_gia hoá_học khí_quyển rachel pike giới_thiệu sơ_lược về những nỗ_lực khoa_học miệt_mài đằng_sau những tiêu_đề táo_bạo về biến_đổi khí_hậu cùng với đoàn nghiên_cứu của mình hàng ngàn người đã cống_hiến cho dự_án này một chuyến bay mạo_hiểm qua rừng_già để tìm_kiếm thông_tin về một phân_tử then_chốt .',\n",
       " 'tôi muốn cho các bạn biết về sự to_lớn của những nỗ_lực khoa_học đã góp_phần làm_nên các dòng tít bạn thường thấy trên báo .',\n",
       " 'có những dòng trông như thế_này khi bàn về biến_đổi khí_hậu và như thế_này khi nói về chất_lượng không_khí hay khói bụi .',\n",
       " 'cả hai đều là một nhánh của cùng một lĩnh_vực trong ngành khoa_học khí_quyển .',\n",
       " 'các tiêu_đề gần_đây trông như thế_này khi ban điều_hành biến_đổi khí_hậu liên_chính_phủ gọi tắt là ipcc đưa ra_bài nghiên_cứu của họ về hệ_thống khí_quyển .',\n",
       " 'nghiên_cứu được viết bởi nhà khoa_học từ quốc_gia khác nhau .',\n",
       " 'họ viết gần trang về chủ_đề này .',\n",
       " 'và tất_cả các trang đều được xem_xét bởi khoa_học gia và nhà phê_bình khác từ quốc_gia .',\n",
       " 'đó là cả một cộng_đồng lớn lớn đến_nỗi trên thực_tế cuộc tụ_hội hằng năm của chúng_tôi là hội_nghị khoa_học [ tự_nhiên ] lớn nhất thế_giới .']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "['khoa_học đằng_sau một tiêu_đề về khí_hậu',\n",
       " 'trong phút chuyên_gia hoá_học khí_quyển rachel pike giới_thiệu sơ_lược về những nỗ_lực khoa_học miệt_mài đằng_sau những tiêu_đề táo_bạo về biến_đổi khí_hậu cùng với đoàn nghiên_cứu của mình hàng ngàn người đã cống_hiến cho dự_án này một chuyến bay mạo_hiểm qua rừng_già để tìm_kiếm thông_tin về một phân_tử then_chốt .',\n",
       " 'tôi muốn cho các bạn biết về sự to_lớn của những nỗ_lực khoa_học đã góp_phần làm_nên các dòng tít bạn thường thấy trên báo .',\n",
       " 'có những dòng trông như thế_này khi bàn về biến_đổi khí_hậu và như thế_này khi nói về chất_lượng không_khí hay khói bụi .',\n",
       " 'cả hai đều là một nhánh của cùng một lĩnh_vực trong ngành khoa_học khí_quyển .',\n",
       " 'các tiêu_đề gần_đây trông như thế_này khi ban điều_hành biến_đổi khí_hậu liên_chính_phủ gọi tắt là ipcc đưa ra_bài nghiên_cứu của họ về hệ_thống khí_quyển .',\n",
       " 'nghiên_cứu được viết bởi nhà khoa_học từ quốc_gia khác nhau .',\n",
       " 'họ viết gần trang về chủ_đề này .',\n",
       " 'và tất_cả các trang đều được xem_xét bởi khoa_học gia và nhà phê_bình khác từ quốc_gia .',\n",
       " 'đó là cả một cộng_đồng lớn lớn đến_nỗi trên thực_tế cuộc tụ_hội hằng năm của chúng_tôi là hội_nghị khoa_học [ tự_nhiên ] lớn nhất thế_giới .']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normalize_train_zh[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EN length @0.8: 138, CH length @0.8: 141\n",
      "EN length @0.8: 143, CH length @0.8: 151\n",
      "EN length @0.8: 121, CH length @0.8: 127\n",
      "EN length @0.8: 138, CH length @0.8: 141\n",
      "EN length @0.8: 143, CH length @0.8: 151\n",
      "EN length @0.8: 121, CH length @0.8: 127\n"
     ]
    }
   ],
   "source": [
    "train_df, pad_len = to_dataframe(normalize_train_en, normalize_train_zh)\n",
    "val_df, _ = to_dataframe(normalize_val_en, normalize_val_zh)\n",
    "test_df, _ = to_dataframe(normalize_test_en, normalize_test_zh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of en words: 41217, ch words: 33913\n",
      "Number of en words: 41217, ch words: 33913\n"
     ]
    }
   ],
   "source": [
    "en_id2token, en_token2id, zh_id2token, zh_token2id = get_vocabulary(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10004\n",
      "10004\n"
     ]
    }
   ],
   "source": [
    "print(len(en_id2token))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_en_indicies = token_to_index(normalize_train_en, en_token2id)\n",
    "val_en_indicies = token_to_index(normalize_val_en, en_token2id)\n",
    "test_en_indicies = token_to_index(normalize_test_en, en_token2id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_zh_indicies = token_to_index(normalize_train_zh, zh_token2id)\n",
    "val_zh_indicies = token_to_index(normalize_val_zh, zh_token2id)\n",
    "test_zh_indicies = token_to_index(normalize_test_zh, zh_token2id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[6225, 3, 4, 289, 548, 9, 661, 5250], [12, 445, 8141, 6034, 6225, 3, 3228, 9, 4103, 8, 4, 1208, 888, 1440, 548, 4, 2660, 3538, 28, 661, 162, 29, 134, 552, 41, 8, 502, 67, 5131, 437, 9, 5132, 1663, 122, 4, 3678, 12, 3610, 8, 208, 28, 9, 698, 1415], [11, 7, 140, 44, 6, 153, 6, 14, 156, 32, 4, 604, 8, 4, 888, 1440, 10, 336, 89, 262, 4, 3538, 14, 72, 12, 4, 569], [3538, 10, 113, 44, 18, 53, 21, 25, 6, 40, 29, 661, 162, 5, 3538, 10, 113, 44, 18, 53, 21, 25, 6, 40, 29, 538, 849, 54, 3], [21, 24, 372, 103, 4879, 8, 4, 144, 673, 8, 8141, 289]]\n",
      "[[183, 1259, 8, 3129, 29, 807], [15, 378, 845, 1021, 1947, 6100, 3, 719, 8746, 29, 9, 996, 183, 6990, 1259, 9, 3129, 2588, 29, 682, 807, 144, 23, 2852, 150, 10, 70, 165, 656, 19, 18, 2997, 26, 304, 21, 8, 582, 441, 1637, 130, 9298, 27, 454, 215, 29, 8, 614, 3803, 4], [7, 68, 26, 16, 11, 59, 29, 37, 935, 10, 9, 996, 183, 18, 2925, 1785, 16, 705, 4570, 11, 247, 56, 53, 637, 4], [13, 9, 705, 350, 49, 375, 36, 653, 29, 682, 807, 5, 49, 375, 36, 47, 29, 1034, 918, 78, 2754, 2288, 4], [103, 113, 117, 6, 8, 3431, 10, 144, 8, 623, 15, 421, 183, 1947, 4]]\n",
      "[[6225, 3, 4, 289, 548, 9, 661, 5250], [12, 445, 8141, 6034, 6225, 3, 3228, 9, 4103, 8, 4, 1208, 888, 1440, 548, 4, 2660, 3538, 28, 661, 162, 29, 134, 552, 41, 8, 502, 67, 5131, 437, 9, 5132, 1663, 122, 4, 3678, 12, 3610, 8, 208, 28, 9, 698, 1415], [11, 7, 140, 44, 6, 153, 6, 14, 156, 32, 4, 604, 8, 4, 888, 1440, 10, 336, 89, 262, 4, 3538, 14, 72, 12, 4, 569], [3538, 10, 113, 44, 18, 53, 21, 25, 6, 40, 29, 661, 162, 5, 3538, 10, 113, 44, 18, 53, 21, 25, 6, 40, 29, 538, 849, 54, 3], [21, 24, 372, 103, 4879, 8, 4, 144, 673, 8, 8141, 289]]\n",
      "[[183, 1259, 8, 3129, 29, 807], [15, 378, 845, 1021, 1947, 6100, 3, 719, 8746, 29, 9, 996, 183, 6990, 1259, 9, 3129, 2588, 29, 682, 807, 144, 23, 2852, 150, 10, 70, 165, 656, 19, 18, 2997, 26, 304, 21, 8, 582, 441, 1637, 130, 9298, 27, 454, 215, 29, 8, 614, 3803, 4], [7, 68, 26, 16, 11, 59, 29, 37, 935, 10, 9, 996, 183, 18, 2925, 1785, 16, 705, 4570, 11, 247, 56, 53, 637, 4], [13, 9, 705, 350, 49, 375, 36, 653, 29, 682, 807, 5, 49, 375, 36, 47, 29, 1034, 918, 78, 2754, 2288, 4], [103, 113, 117, 6, 8, 3431, 10, 144, 8, 623, 15, 421, 183, 1947, 4]]\n"
     ]
    }
   ],
   "source": [
    "print(train_en_indicies[:5])\n",
    "print(train_zh_indicies[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------------------------------------\n",
      "File exists, load from path...\n",
      "----------------------------------------------------------------------------------------------------\n",
      "File exists, load from path...\n",
      "----------------------------------------------------------------------------------------------------\n",
      "File exists, load from path...\n",
      "----------------------------------------------------------------------------------------------------\n",
      "File exists, load from path...\n",
      "----------------------------------------------------------------------------------------------------\n",
      "File exists, load from path...\n",
      "----------------------------------------------------------------------------------------------------\n",
      "File exists, load from path...\n",
      "----------------------------------------------------------------------------------------------------\n",
      "File exists, load from path...\n",
      "----------------------------------------------------------------------------------------------------\n",
      "File exists, load from path...\n"
     ]
    }
   ],
   "source": [
    "en_pretrain_emb, zh_pretrain_emb = [], []\n",
    "print ('-'*100)\n",
    "en_pretrain_emb = load_pickle('en_pretrain_emb_vim.p', load_vectors, en_pretrained_path)\n",
    "print ('-'*100)\n",
    "eng_embedding, _ = load_pickle('eng_embedding_vim.p', get_embedding_weights, en_pretrain_emb, en_id2token)\n",
    "del en_pretrain_emb\n",
    "print ('-'*100)\n",
    "zh_pretrain_emb = load_pickle('zh_pretrain_emb_vim.p', load_vectors, zh_pretrained_path)\n",
    "print ('-'*100)\n",
    "zh_embedding, _ = load_pickle('zh_embedding_vim.p', get_embedding_weights, zh_pretrain_emb, zh_id2token)\n",
    "del zh_pretrain_emb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10004, 300)\n",
      "(10004, 300)\n"
     ]
    }
   ],
   "source": [
    "print(zh_embedding.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LanguageDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Class that represents a train/validation/test dataset that's readable for PyTorch\n",
    "    Note that this class inherits torch.utils.data.Dataset\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, source_lan, translate_lan):\n",
    "        \"\"\"\n",
    "        @param data_list: list of character\n",
    "        @param target_list: list of targets\n",
    "\n",
    "        \"\"\"\n",
    "        self.source_lan = source_lan\n",
    "        self.translate_lan = translate_lan\n",
    "        \n",
    "        assert (len(self.source_lan) == len(self.translate_lan))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.source_lan)\n",
    "\n",
    "    def __getitem__(self, key):\n",
    "        \"\"\"\n",
    "        Triggered when you call dataset[i]\n",
    "        \"\"\"\n",
    "        source_lan_idx = self.source_lan[key][:MAX_SENTENCE_LENGTH-1]\n",
    "        translation_lan_idx = self.translate_lan[key][:MAX_SENTENCE_LENGTH-1]\n",
    "        source_lan_idx.append(EOS_idx)\n",
    "        translation_lan_idx.append(EOS_idx)\n",
    "        \n",
    "        return [source_lan_idx, translation_lan_idx, len(source_lan_idx), len(translation_lan_idx)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vocab_collate_func(batch):\n",
    "    \"\"\"\n",
    "    Customized function for DataLoader that dynamically pads the batch so that all\n",
    "    data have the same length\n",
    "    \"\"\"\n",
    "    source_list = []\n",
    "    translate_list = []\n",
    "    length_list = []\n",
    "    \n",
    "    # padding\n",
    "    for datum in batch:\n",
    "\n",
    "        length_list.append(datum[2])\n",
    "        s_padded_vec = np.pad(np.array(datum[0]),\n",
    "                                pad_width=((0,MAX_SENTENCE_LENGTH-datum[2])),\n",
    "                                mode=\"constant\", constant_values=PAD_idx)\n",
    "        source_list.append(s_padded_vec)\n",
    "        t_padded_vec = np.pad(np.array(datum[1]),\n",
    "                                pad_width=((0,MAX_SENTENCE_LENGTH-datum[3])),\n",
    "                                mode=\"constant\", constant_values=PAD_idx)\n",
    "        translate_list.append(t_padded_vec)\n",
    "        \n",
    "#     ind_dec_order = np.argsort(length_list)[::-1]\n",
    "#     source_list = np.array(source_list)[ind_dec_order]\n",
    "#     length_list = np.array(length_list)[ind_dec_order]\n",
    "#     translate_list = np.array(translate_list)[ind_dec_order]\n",
    "    \n",
    "    if torch.cuda.is_available and torch.has_cudnn:\n",
    "        return [torch.from_numpy(np.array(source_list)).cuda(),torch.from_numpy(np.array(translate_list)).cuda()]\n",
    "    else:\n",
    "        return [torch.from_numpy(np.array(source_list)),torch.from_numpy(np.array(translate_list))]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = LanguageDataset(train_zh_indicies, train_en_indicies)\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
    "                                           batch_size=batch_size,\n",
    "                                           collate_fn=vocab_collate_func,\n",
    "                                           shuffle=True)\n",
    "\n",
    "s_train_dataset = LanguageDataset(train_zh_indicies[2000:2500], train_en_indicies[2000:2500])\n",
    "s_train_loader = torch.utils.data.DataLoader(dataset=s_train_dataset,\n",
    "                                           batch_size=batch_size,\n",
    "                                           collate_fn=vocab_collate_func,\n",
    "                                           shuffle=True)\n",
    "\n",
    "val_dataset = LanguageDataset(val_zh_indicies, val_en_indicies)\n",
    "val_loader = torch.utils.data.DataLoader(dataset=val_dataset,\n",
    "                                           batch_size=batch_size,\n",
    "                                           collate_fn=vocab_collate_func,\n",
    "                                           shuffle=False)\n",
    "\n",
    "test_dataset = LanguageDataset(test_zh_indicies, test_en_indicies)\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset,\n",
    "                                           batch_size=batch_size,\n",
    "                                           collate_fn=vocab_collate_func,\n",
    "                                           shuffle=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10004, 300)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(10004, 300)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zh_embedding.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rnn Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderRNN(nn.Module):\n",
    "    def __init__(self, emb_dim, hid_dim):\n",
    "        super(EncoderRNN, self).__init__()\n",
    "        \n",
    "        self.hid_dim = hid_dim\n",
    "        self.embedding = nn.Embedding.from_pretrained(torch.from_numpy(zh_embedding), freeze=False)\n",
    "        self.dropout = nn.Dropout(p=0.2)\n",
    "        self.gru = nn.GRU(emb_dim, hid_dim, batch_first=True, bidirectional=True)\n",
    "\n",
    "    def forward(self, inputs, hidden):\n",
    "        encode_batch_size, length = inputs.size()\n",
    "        \n",
    "        embedded = self.dropout(self.embedding(inputs).float()) # the size -1 is inferred from other dimensions\n",
    "        outputs, hidden = self.gru(embedded, hidden)\n",
    "        outputs = outputs[:, :, :self.hid_dim] + outputs[:, :, self.hid_dim:]\n",
    "        outputs = outputs.transpose(0,1)\n",
    "        hidden = hidden[0:1,:,:] + hidden[1:2,:,:]\n",
    "        #print(outputs.shape, hidden.shape)\n",
    "        return outputs, hidden #[T*B*H], [1*B*H]\n",
    "\n",
    "    def init_hidden(self, encode_batch_size):\n",
    "        \n",
    "        return torch.zeros(2, encode_batch_size, self.hid_dim, device=device)\n",
    "    \n",
    "class ConvEncoderRNN(nn.Module):\n",
    "    def __init__(self, emb_dim, hid_dim):\n",
    "        super(ConvEncoderRNN, self).__init__()\n",
    "        \n",
    "        self.hid_dim = hid_dim\n",
    "        self.embedding = nn.Embedding.from_pretrained(torch.from_numpy(zh_embedding), freeze=False)\n",
    "        self.dropout = nn.Dropout(p=0.2)\n",
    "        self.conv1 = nn.Conv1d(emb_dim, hid_dim, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv1d(hid_dim, hid_dim, kernel_size=3, padding=1)\n",
    "        self.conv3 = nn.Conv1d(hid_dim, hid_dim, kernel_size=3, padding=1)\n",
    "        self.conv4 = nn.Conv1d(hid_dim, hid_dim, kernel_size=3, padding=1)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        batch_size, seq_len1 = inputs.size()\n",
    "        \n",
    "        embedded = self.dropout(self.embedding(inputs).float()) # B*T*EMD\n",
    "        hidden1 = self.conv1(embedded.transpose(1,2)).transpose(1,2)\n",
    "        hidden1 = F.relu(hidden1.contiguous().view(-1, hidden1.size(-1))).view(batch_size, seq_len1, hidden1.size(-1))\n",
    "        hidden1 = self.conv2(hidden1.transpose(1,2)).transpose(1,2)\n",
    "        hidden1 = F.relu(hidden1.contiguous().view(-1, hidden1.size(-1))).view(batch_size, seq_len1, hidden1.size(-1))\n",
    "        \n",
    "        hidden1 = self.conv3(hidden1.transpose(1,2)).transpose(1,2)\n",
    "        hidden1 = F.relu(hidden1.contiguous().view(-1, hidden1.size(-1))).view(batch_size, seq_len1, hidden1.size(-1))\n",
    "        hidden1 = self.conv4(hidden1.transpose(1,2)).transpose(1,2)\n",
    "        hidden1 = F.relu(hidden1.contiguous().view(-1, hidden1.size(-1))).view(batch_size, seq_len1, hidden1.size(-1))\n",
    "        \n",
    "        outputs = hidden1.transpose(0,1)\n",
    "        hidden = torch.sum(hidden1, dim=1).unsqueeze(0)\n",
    "        #print(outputs.shape, hidden.shape)\n",
    "        \n",
    "        return outputs, hidden #[T*B*H], [1*B*H]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decoder w/o Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Attention(nn.Module):\n",
    "    def __init__(self, hidden_size):\n",
    "        super(Attention, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.attn = nn.Linear(self.hidden_size * 2, hidden_size)\n",
    "        self.v = nn.Parameter(torch.rand(hidden_size))\n",
    "        stdv = 1. / math.sqrt(self.v.size(0))\n",
    "        self.v.data.uniform_(-stdv, stdv)\n",
    "\n",
    "    def forward(self, hidden, encoder_outputs):#[B*H], [T*B*H]\n",
    "        timestep = encoder_outputs.size(0)  #T\n",
    "        h = hidden.repeat(timestep, 1, 1).transpose(0, 1) #[B*T*H]\n",
    "        encoder_outputs = encoder_outputs.transpose(0, 1)  # [B*T*H]\n",
    "        attn_energies = self.score(h, encoder_outputs) #[B*T]\n",
    "        return F.softmax(attn_energies, dim=1).unsqueeze(1) #[B*1*T]\n",
    "\n",
    "    def score(self, hidden, encoder_outputs):\n",
    "        # [B*T*2H]->[B*T*H]\n",
    "        energy = F.relu(self.attn(torch.cat([hidden, encoder_outputs], 2)))\n",
    "        energy = energy.transpose(1, 2)  # [B*H*T]\n",
    "        v = self.v.repeat(encoder_outputs.size(0), 1).unsqueeze(1)  # [B*1*H]\n",
    "        energy = torch.bmm(v, energy)  # [B*1*T]\n",
    "        return energy.squeeze(1)  # [B*T]\n",
    "    \n",
    "class dotproduct_att(nn.Module):\n",
    "    def __init__(self, hidden_size):\n",
    "        super(dotproduct_att, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.attn1 = nn.Linear(self.hidden_size, hidden_size)\n",
    "        self.attn2 = nn.Linear(self.hidden_size, hidden_size)\n",
    "\n",
    "\n",
    "    def forward(self, hidden, encoder_outputs):#[B*H], [T*B*H]\n",
    "        timestep = encoder_outputs.size(0)  #T\n",
    "        #h = hidden.repeat(timestep, 1, 1).transpose(0, 1) #[B*T*H]\n",
    "        encoder_outputs = self.attn1(encoder_outputs.transpose(0, 1)).transpose(1,2)  # [B*H*T]\n",
    "        attn_energies = torch.bmm(self.attn2(hidden).unsqueeze(1), encoder_outputs) #[B*T]\n",
    "        return F.softmax(attn_energies, dim=2) #[B*1*T]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderRNN(nn.Module):\n",
    "    def __init__(self, emb_dim, hid_dim, output_dim):\n",
    "        super(DecoderRNN, self).__init__()\n",
    "        self.emb_dim = emb_dim\n",
    "        self.hid_dim = hid_dim\n",
    "        self.output_dim = output_dim\n",
    "        self.dropout1 = nn.Dropout(p=0.2)\n",
    "        self.embedding = nn.Embedding.from_pretrained(torch.from_numpy(eng_embedding), freeze=False)\n",
    "        self.mapping = nn.Linear(self.emb_dim+self.hid_dim, self.hid_dim)\n",
    "        #self.attention = Attention(hid_dim)\n",
    "        self.attention = Attention(hid_dim)\n",
    "        self.gru = nn.GRU(emb_dim+hid_dim, hid_dim)\n",
    "        \n",
    "        self.out = nn.Linear(hid_dim * 2, output_dim)\n",
    "        \n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "\n",
    "    def forward(self, inputs, last_hidden, encoder_outputs): #encoder_outputs: [T*B*H]\n",
    "        \n",
    "        emb = self.dropout1(self.embedding(inputs).float()) #[1*B*EMB_DIM]\n",
    "        attn_keys = self.mapping(torch.cat((emb, last_hidden), dim=2))\n",
    "        attn_weights = self.attention(attn_keys[-1], encoder_outputs) #[[B*1*T]]\n",
    "        \n",
    "        context = attn_weights.bmm(encoder_outputs.transpose(0, 1))  # (B,1,H)\n",
    "        context = context.transpose(0, 1)  # (1,B,H)\n",
    "        \n",
    "        rnn_input = torch.cat([emb, context], 2) #[1*B*(EMD_DIM+H)]\n",
    "\n",
    "        output, hidden = self.gru(rnn_input, last_hidden) #[1*B*H], [1*B*H]\n",
    "        output = output.squeeze(0)  # (1,B,H) -> (B,H)\n",
    "        context = context.squeeze(0) # (1,B,H) -> [B*H]\n",
    "        output = self.out(torch.cat([output, context], 1)) #[B*2H]\n",
    "        output = self.softmax(output) #[B, output_dim]\n",
    "        \n",
    "        \n",
    "        return output, hidden, attn_weights\n",
    "    \n",
    "# class Decoder(nn.Module):\n",
    "#     def __init__(self, embed_size, hidden_size, output_size,\n",
    "#                  n_layers=1, dropout=0.2):\n",
    "#         super(Decoder, self).__init__()\n",
    "#         self.embed_size = embed_size\n",
    "#         self.hidden_size = hidden_size\n",
    "#         self.output_size = output_size\n",
    "#         self.n_layers = n_layers\n",
    "\n",
    "#         self.embed = nn.Embedding.from_pretrained(torch.from_numpy(eng_embedding), freeze=True)\n",
    "#         self.dropout = nn.Dropout(dropout, inplace=True)\n",
    "#         self.attention = Attention(hidden_size)\n",
    "#         self.gru = nn.GRU(hidden_size + embed_size, hidden_size,\n",
    "#                           n_layers, dropout=dropout)\n",
    "#         self.out = nn.Linear(hidden_size * 2, output_size)\n",
    "\n",
    "#     def forward(self, input, last_hidden, encoder_outputs):\n",
    "#         # Get the embedding of the current input word (last output word)\n",
    "#         embedded = self.embed(input)  # (1,B,N)\n",
    "#         embedded = self.dropout(embedded)\n",
    "#         # Calculate attention weights and apply to encoder outputs\n",
    "#         attn_weights = self.attention(last_hidden[-1], encoder_outputs)\n",
    "#         context = attn_weights.bmm(encoder_outputs.transpose(0, 1))  # (B,1,N)\n",
    "#         context = context.transpose(0, 1)  # (1,B,N)\n",
    "#         # Combine embedded input word and attended context, run through RNN\n",
    "#         rnn_input = torch.cat([embedded, context], 2)\n",
    "#         output, hidden = self.gru(rnn_input, last_hidden)\n",
    "#         output = output.squeeze(0)  # (1,B,N) -> (B,N)\n",
    "#         context = context.squeeze(0)\n",
    "#         output = self.out(torch.cat([output, context], 1))\n",
    "#         output = F.log_softmax(output, dim=1)\n",
    "#         return output, hidden, attn_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class Encoder(nn.Module):\n",
    "#     def __init__(self, embed_size, hidden_size, n_layers=1, dropout=0.2):\n",
    "#         super(Encoder, self).__init__()\n",
    "#         self.input_size = input_size\n",
    "#         self.hidden_size = hidden_size\n",
    "#         self.embed_size = embed_size\n",
    "#         self.embed = nn.Embedding.from_pretrained(torch.from_numpy(zh_embedding), freeze=False)\n",
    "#         self.gru = nn.GRU(embed_size, hidden_size, n_layers, dropout=dropout, bidirectional=True, batch_first=True)\n",
    "\n",
    "#     def forward(self, src, hidden=None):\n",
    "#         embedded = self.embed(src)\n",
    "#         outputs, hidden = self.gru(embedded, hidden)\n",
    "#         # sum bidirectional outputs\n",
    "#         outputs = (outputs[:, :, :self.hidden_size] +\n",
    "#                    outputs[:, :, self.hidden_size:])\n",
    "#         hidden = hidden = hidden[0:1,:,:]\n",
    "#         return outputs, hidden\n",
    "    \n",
    "#     def init_hidden(self, encode_batch_size):\n",
    "#         return torch.ones(2, encode_batch_size, self.hidden_size, device=device)\n",
    "\n",
    "# class Attention(nn.Module):\n",
    "#     def __init__(self, hidden_size):\n",
    "#         super(Attention, self).__init__()\n",
    "#         self.hidden_size = hidden_size\n",
    "#         self.attn = nn.Linear(self.hidden_size * 2, hidden_size)\n",
    "#         self.v = nn.Parameter(torch.rand(hidden_size))\n",
    "#         stdv = 1. / math.sqrt(self.v.size(0))\n",
    "#         self.v.data.uniform_(-stdv, stdv)\n",
    "\n",
    "#     def forward(self, hidden, encoder_outputs):\n",
    "#         timestep = encoder_outputs.size(0)\n",
    "#         h = hidden.repeat(timestep, 1, 1).transpose(0, 1)\n",
    "#         encoder_outputs = encoder_outputs.transpose(0, 1)  # [B*T*H]\n",
    "#         attn_energies = self.score(h, encoder_outputs)\n",
    "#         return F.relu(attn_energies, dim=1).unsqueeze(1)\n",
    "\n",
    "#     def score(self, hidden, encoder_outputs):\n",
    "#         # [B*T*2H]->[B*T*H]\n",
    "#         energy = F.softmax(self.attn(torch.cat([hidden, encoder_outputs], 2)))\n",
    "#         energy = energy.transpose(1, 2)  # [B*H*T]\n",
    "#         v = self.v.repeat(encoder_outputs.size(0), 1).unsqueeze(1)  # [B*1*H]\n",
    "#         energy = torch.bmm(v, energy)  # [B*1*T]\n",
    "#         return energy.squeeze(1)  # [B*T]\n",
    "\n",
    "\n",
    "# class Decoder(nn.Module):\n",
    "#     def __init__(self, embed_size, hidden_size, output_size,\n",
    "#                  n_layers=1, dropout=0.2):\n",
    "#         super(Decoder, self).__init__()\n",
    "#         self.embed_size = embed_size\n",
    "#         self.hidden_size = hidden_size\n",
    "#         self.output_size = output_size\n",
    "#         self.n_layers = n_layers\n",
    "\n",
    "#         self.embed = nn.Embedding.from_pretrained(torch.from_numpy(eng_embedding), freeze=True)\n",
    "#         self.dropout = nn.Dropout(dropout, inplace=True)\n",
    "#         self.attention = Attention(hidden_size)\n",
    "#         self.gru = nn.GRU(hidden_size + embed_size, hidden_size,\n",
    "#                           n_layers, dropout=dropout)\n",
    "#         self.out = nn.Linear(hidden_size * 2, output_size)\n",
    "\n",
    "#     def forward(self, input, last_hidden, encoder_outputs):\n",
    "#         # Get the embedding of the current input word (last output word)\n",
    "#         embedded = self.embed(input)  # (1,B,N)\n",
    "#         embedded = self.dropout(embedded)\n",
    "#         # Calculate attention weights and apply to encoder outputs\n",
    "#         attn_weights = self.attention(last_hidden[-1], encoder_outputs)\n",
    "#         context = attn_weights.bmm(encoder_outputs.transpose(0, 1))  # (B,1,N)\n",
    "#         context = context.transpose(0, 1)  # (1,B,N)\n",
    "#         # Combine embedded input word and attended context, run through RNN\n",
    "#         rnn_input = torch.cat([embedded, context], 2)\n",
    "#         output, hidden = self.gru(rnn_input, last_hidden)\n",
    "#         output = output.squeeze(0)  # (1,B,N) -> (B,N)\n",
    "#         context = context.squeeze(0)\n",
    "#         output = self.out(torch.cat([output, context], 1))\n",
    "#         output = F.log_softmax(output, dim=1)\n",
    "#         return output, hidden, attn_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "teacher_forcing_ratio = 0.95\n",
    "#input_tensor: list of sentence tensor\n",
    "def train(source, translate, encoder, decoder, encoder_optimizer, decoder_optimizer,\n",
    "          criterion):\n",
    "    encoder.train()\n",
    "    decoder.train()\n",
    "    cur_batch_size, input_length = source.size()\n",
    "    cur_batch_size, target_length = translate.size()\n",
    "    \n",
    "    \n",
    "    encoder_hidden = encoder.init_hidden(cur_batch_size)\n",
    "\n",
    "    encoder_optimizer.zero_grad()\n",
    "    decoder_optimizer.zero_grad()\n",
    "\n",
    "    loss = 0\n",
    "    #hidden = [1, batch size, hid dim]\n",
    "    #encoder_output = [batch size, sen len, hid dim]\n",
    "    \n",
    "    encoder_output, encoder_hidden = encoder(source, encoder_hidden)\n",
    "    #encoder_output, encoder_hidden = encoder(source)\n",
    "\n",
    "    decoder_input = torch.tensor(np.array([[SOS_idx]]*cur_batch_size).reshape(1,cur_batch_size),device=device)\n",
    "    decoder_hidden = encoder_hidden\n",
    "\n",
    "    use_teacher_forcing = True if random.random() < teacher_forcing_ratio else False\n",
    "    if use_teacher_forcing:\n",
    "        # Teacher forcing: Feed the target as the next input\n",
    "        for i in range(target_length):\n",
    "        \n",
    "            \n",
    "            decoder_output, decoder_hidden, decoder_attention = decoder(decoder_input, decoder_hidden, encoder_output)\n",
    "            \n",
    "            loss += criterion(decoder_output, translate[:,i])\n",
    "            decoder_input = translate[:,i].unsqueeze(0)  # Teacher forcing\n",
    "            \n",
    "    else:\n",
    "        # Without teacher forcing: use its own predictions as the next input\n",
    "        for i in range(target_length):\n",
    "            decoder_output, decoder_hidden, decoder_attention= decoder(decoder_input, decoder_hidden, encoder_output)\n",
    "            topv, topi = decoder_output.topk(1)\n",
    "            decoder_input = topi.squeeze().detach()  # detach from history as input\n",
    "            \n",
    "            #decoder_input [1, batch size] \n",
    "            decoder_input = decoder_input.unsqueeze(0)\n",
    " \n",
    "            loss += criterion(decoder_output, translate[:,i])\n",
    "\n",
    "    loss.backward()\n",
    "\n",
    "    encoder_optimizer.step()\n",
    "    decoder_optimizer.step()\n",
    "\n",
    "    return loss.item() / target_length\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate2(encoder, decoder, loader):\n",
    "    encoder.eval()\n",
    "    decoder.eval()\n",
    "    input_words = []\n",
    "    target_words = []\n",
    "    decoded_words = []\n",
    "    num_count = 0\n",
    "    num_count = 0\n",
    "    for i, (source, translate) in enumerate(loader):\n",
    "\n",
    "        cur_batch_size = translate.size()[0]\n",
    "        #print('cur_batch_size: ',cur_batch_size)\n",
    "            \n",
    "        with torch.no_grad():\n",
    "            encoder_hidden = encoder.init_hidden(cur_batch_size)\n",
    "        \n",
    "        input_tensor = source\n",
    "        target_tensor = translate\n",
    "        target_length = target_tensor.size()[1]\n",
    "        #print('encoder_hidden shape: ', encoder_hidden.size())\n",
    "        encoder_output, encoder_hidden = encoder(input_tensor, encoder_hidden)\n",
    "        #encoder_output, encoder_hidden = encoder(input_tensor)\n",
    "\n",
    "        decoder_input = torch.tensor(np.array([[SOS_idx]]*cur_batch_size).reshape(1,cur_batch_size),device=device)\n",
    "        decoder_hidden = encoder_hidden\n",
    "        \n",
    "        for i in range(cur_batch_size):\n",
    "            decoded_words.append([])\n",
    "            input_words.append([])\n",
    "            target_words.append([])\n",
    "        \n",
    "        for i in range(cur_batch_size):\n",
    "            for ii in range(input_tensor.size()[1]):\n",
    "                if zh_id2token[input_tensor.cpu().numpy()[i,ii]] != '<PAD>':\n",
    "                    input_words[num_count].append(zh_id2token[input_tensor.cpu().numpy()[i,ii]])\n",
    "            num_count += 1\n",
    "        num_count -= cur_batch_size\n",
    "        for i in range(cur_batch_size):\n",
    "            for ii in range(target_tensor.size()[1]):\n",
    "                if en_id2token[target_tensor.cpu().numpy()[i,ii]] != '<PAD>':\n",
    "                    target_words[num_count].append(en_id2token[target_tensor.cpu().numpy()[i,ii]])\n",
    "            num_count += 1\n",
    "        num_count -= cur_batch_size      \n",
    "        \n",
    "        cur_len = np.zeros(cur_batch_size, dtype=int)\n",
    "        #pdb.set_trace()\n",
    "        for i in range(target_length):\n",
    "            decoder_output, decoder_hidden, decoder_attention = decoder(decoder_input, decoder_hidden, encoder_output)\n",
    "            topv, topi = decoder_output.topk(1)\n",
    "            decoder_input = topi.squeeze().detach()  # detach from history as input\n",
    "            decoder_input = decoder_input.unsqueeze(0)\n",
    "            \n",
    "            topi = topi.squeeze().cpu().numpy()\n",
    "            if cur_len[0] == 0:\n",
    "                for i in range(len(topi)):\n",
    "                    decoded_words[num_count+i].append(en_id2token[topi[i]])\n",
    "                    cur_len[i] += 1\n",
    "            \n",
    "            else:\n",
    "                for i in range(len(topi)):\n",
    "                    if decoded_words[num_count+i][cur_len[i]-1] == '<EOS>':\n",
    "                        continue\n",
    "                    decoded_words[num_count+i].append(en_id2token[topi[i]])\n",
    "                    cur_len[i] += 1\n",
    "        num_count += cur_batch_size\n",
    "    pre_list = []\n",
    "    for pre_sentenc in decoded_words:\n",
    "        pre_list.append(\"\".join([\" \"+i if not i.startswith(\"'\") and i not in string.punctuation else i for i in pre_sentenc]).strip())\n",
    "\n",
    "    true_list = []\n",
    "    for true_sentenc in target_words:\n",
    "        true_list.append(\"\".join([\" \"+i if not i.startswith(\"'\") and i not in string.punctuation else i for i in true_sentenc]).strip())\n",
    "    \n",
    "    true_list2 = []\n",
    "    true_list2.append(true_list)        \n",
    "    score = sacrebleu.corpus_bleu(pre_list, true_list2)\n",
    "    #score = sacrebleu.raw_corpus_bleu(pre_list, true_list2)\n",
    "    print('bleu score: ', score.score)\n",
    "    return decoded_words,input_words, target_words, score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainIters(encoder, decoder, n_iters, print_every=500, plot_every=200, learning_rate=0.001):\n",
    "    start = time.time()\n",
    "    plot_losses = []\n",
    "    print_loss_total = 0  # Reset every print_every\n",
    "    plot_loss_total = 0  # Reset every plot_every\n",
    "\n",
    "    encoder_optimizer = optim.Adam(encoder.parameters(), lr=learning_rate)\n",
    "    decoder_optimizer = optim.Adam(decoder.parameters(), lr=learning_rate)\n",
    "    criterion = nn.NLLLoss(ignore_index = 0)\n",
    "    count_iter = 0\n",
    "    for cur_iter in range(1, n_iters + 1):\n",
    "        for i, (source, translate) in enumerate(train_loader):\n",
    "            \n",
    "            loss = train(source, translate, encoder,\n",
    "                         decoder, encoder_optimizer, decoder_optimizer, criterion)\n",
    "            print_loss_total += loss\n",
    "            plot_loss_total += loss\n",
    "            count_iter += 1\n",
    "            if count_iter % print_every == 0:\n",
    "                torch.save(encoder.state_dict(), './model/encoder_stable_ATT_ming_vim.pth')\n",
    "                torch.save(decoder.state_dict(), './model/decoder_stable_ATT_ming_vim.pth')\n",
    "                print_loss_avg = print_loss_total / print_every\n",
    "                print_loss_total = 0\n",
    "                print('%d %d%% %.4f' % (cur_iter, cur_iter / n_iters * 100, print_loss_avg))\n",
    "                print('validation: ')\n",
    "                _,_,_, score = evaluate2(encoder, decoder, val_loader)\n",
    "                with open('out5.txt', 'a') as file:\n",
    "                    file.write('validation: ' + str(score.score) + '\\n')\n",
    "                print('small train: ')\n",
    "                _,_,_, score = evaluate2(encoder, decoder, s_train_loader)\n",
    "                with open('out5.txt', 'a') as file:\n",
    "                    file.write('small train: ' + str(score.score) + '\\n')\n",
    "\n",
    "            if count_iter % plot_every == 0:\n",
    "                plot_loss_avg = plot_loss_total / plot_every\n",
    "                plot_losses.append(plot_loss_avg)\n",
    "                plot_loss_total = 0\n",
    "    \n",
    "    \n",
    "    showPlot(plot_losses)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.switch_backend('agg')\n",
    "import matplotlib.ticker as ticker\n",
    "import numpy as np\n",
    "#%matplotlib inline\n",
    "\n",
    "def showPlot(points):\n",
    "    plt.figure()\n",
    "    fig, ax = plt.subplots()\n",
    "    # this locator puts ticks at regular intervals\n",
    "    loc = ticker.MultipleLocator(base=0.2)\n",
    "    ax.yaxis.set_major_locator(loc)\n",
    "    plt.plot(points)\n",
    "    plt.show()\n",
    "    \n",
    "import time\n",
    "import math\n",
    "\n",
    "def asMinutes(s):\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)\n",
    "\n",
    "\n",
    "def timeSince(since, percent):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    es = s / (percent)\n",
    "    rs = es - s\n",
    "    return '%s (- %s)' % (asMinutes(s), asMinutes(rs))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "ENC_EMB_DIM = 300\n",
    "ZH_EMB_DIM = 300\n",
    "HID_DIM = 300\n",
    "OUTPUT_DIM = len(zh_id2token)\n",
    "\n",
    "\n",
    "#encoder = ConvEncoderRNN(ENC_EMB_DIM, HID_DIM).to(device)\n",
    "encoder = EncoderRNN(ENC_EMB_DIM, HID_DIM).to(device)\n",
    "decoder = DecoderRNN(ZH_EMB_DIM, HID_DIM, OUTPUT_DIM).to(device)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "trainIters(encoder, decoder, 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save(encoder.state_dict(), './model/encoder_stable_ATT_ming_vim.pth')\n",
    "# torch.save(decoder.state_dict(), './model/decoder_stable_ATT_ming_vim.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder.load_state_dict(torch.load('./model/encoder_stable_ATT_ming_vim.pth'))\n",
    "decoder.load_state_dict(torch.load('./model/decoder_stable_ATT_ming_vim.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# source = normalizeZh('他 还 上传 了 许多 自然 自然景观 景观 的 视频')\n",
    "# print(source)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import font_manager\n",
    "\n",
    "fontP = font_manager.FontProperties(fname='/home/zq415/msyh.ttf')\n",
    "# fontP.set_family('SimHei')\n",
    "\n",
    "# import pandas as pd\n",
    "# import matplotlib.pyplot as plt\n",
    "# import matplotlib.font_manager as fm\n",
    "# font = fm.FontProperties(fname='c:\\\\windows\\\\fonts\\\\simsun.ttc')  # speicify font\n",
    "# ax = most_active_posts.plot(x = 'title',y = 'active_span',kind = 'barh')\n",
    "# ax.set_xticklabels(most_active_posts['title'].str.decode('utf-8'), fontproperties=font)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def showAttention(input_sentence, output_words, attentions):\n",
    "    # Set up figure with colorbar\n",
    "    max_len = max(len(input_sentence.split(' ')), len(output_words))\n",
    "    attentions = attentions[:max_len+1, :max_len+1]\n",
    "    plt.matshow(attentions.numpy())\n",
    "    fig = plt.figure(figsize=(10,10))\n",
    "    ax = fig.add_subplot(111)\n",
    "    cax = ax.matshow(attentions.numpy(), cmap='bone')\n",
    "    fig.colorbar(cax)\n",
    "\n",
    "    # Set up axes .encode('utf-8').decode(\n",
    "    ax.set_xticklabels([''] + [i for i in input_sentence.split(' ')] +\n",
    "                       ['<EOS>'], rotation=90,fontproperties=fontP,fontsize=10)\n",
    "    ax.set_yticklabels([''] + output_words,fontsize=10)\n",
    "\n",
    "    # Show label at every tick\n",
    "    ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "    ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_visulization(encoder, decoder, source = u'Hãy tưởng tượng mảnh đầu tiên: một người đàn ông đốt cháy sự nghiệp cả đời mình'):\n",
    "    encoder.eval()\n",
    "    decoder.eval()\n",
    "    \n",
    "    norm_source = [normalizeZh(source)]\n",
    "    source_idx = token_to_index(norm_source, zh_token2id)[0]\n",
    "    source_idx.append(EOS_idx)\n",
    "    source_idx_pad = np.pad(np.array(source_idx),\n",
    "                                pad_width=((0,MAX_SENTENCE_LENGTH-len(source_idx))),\n",
    "                                mode=\"constant\", constant_values=PAD_idx)\n",
    "    \n",
    "    source_idx_pad_tensor = torch.from_numpy(np.array(source_idx_pad)).unsqueeze(0).cuda()\n",
    "    \n",
    "\n",
    "    cur_batch_size = 1\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        encoder_hidden = encoder.init_hidden(cur_batch_size)\n",
    "\n",
    "    input_tensor = source_idx_pad_tensor\n",
    "    \n",
    "    encoder_output, encoder_hidden = encoder(input_tensor, encoder_hidden)\n",
    "\n",
    "    \n",
    "    decoder_input = torch.tensor(np.array([[SOS_idx]]*cur_batch_size).reshape(1,cur_batch_size),device=device)\n",
    "    decoder_hidden = encoder_hidden\n",
    "\n",
    "    decoded_words = []\n",
    "    decoded_att = []\n",
    "    decoder_attentions = torch.zeros(MAX_SENTENCE_LENGTH, MAX_SENTENCE_LENGTH)\n",
    "    cur_len = 0\n",
    "    for i in range(MAX_SENTENCE_LENGTH):\n",
    "        decoder_output, decoder_hidden, decoder_attention = decoder(decoder_input, decoder_hidden, encoder_output)\n",
    "        decoder_attentions[cur_len] = decoder_attention.data\n",
    "        topv, topi = decoder_output.topk(1)\n",
    "        decoder_input = topi.squeeze().detach()  # detach from history as input\n",
    "        decoder_input = decoder_input.unsqueeze(0).reshape(1,cur_batch_size)\n",
    "        \n",
    "        topi = topi.squeeze().cpu().numpy()\n",
    "        if cur_len == 0:\n",
    "            decoded_words.append(en_id2token[topi])\n",
    "            cur_len += 1\n",
    "        else:\n",
    "            if decoded_words[cur_len-1] == '<EOS>':\n",
    "                break\n",
    "            else:\n",
    "                decoded_words.append(en_id2token[topi])\n",
    "                cur_len += 1\n",
    "                \n",
    "    return decoded_words, source, decoder_attentions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoded_words, source, decoder_attentions = evaluate_visulization(encoder, decoder)#, source = u'在 自创 流行 行文 文化 中 我们 都 有 自主 自主权 主权')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2b3b73257c88>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2b3b73257c88>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2b3b73421630>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2b3b73421630>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "showAttention(source, decoded_words, decoder_attentions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encoder.load_state_dict(torch.load('./model/encoder_3.pth'))\n",
    "# decoder.load_state_dict(torch.load('./model/encoder_3.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'evaluate_beam' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-47-a433e5956864>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m                                            shuffle=False)\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mdecoded_words\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate_beam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loader2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbeam_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mMAX_SENTENCE_LENGTH\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0moutput_words\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_words\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_words\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscore\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mevaluate2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'evaluate_beam' is not defined"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'evaluate_beam' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-47-a433e5956864>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m                                            shuffle=False)\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mdecoded_words\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate_beam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loader2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbeam_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mMAX_SENTENCE_LENGTH\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0moutput_words\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_words\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_words\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscore\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mevaluate2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'evaluate_beam' is not defined"
     ]
    }
   ],
   "source": [
    "val_dataset2 = LanguageDataset(val_zh_indicies, val_en_indicies)\n",
    "val_loader2 = torch.utils.data.DataLoader(dataset=val_dataset2,\n",
    "                                           batch_size=1,\n",
    "                                           collate_fn=vocab_collate_func,\n",
    "                                           shuffle=False)\n",
    "\n",
    "decoded_words = evaluate_beam(encoder, decoder, val_loader2, beam_size=2, max_length=MAX_SENTENCE_LENGTH)\n",
    "output_words, input_words, target_words, score= evaluate2(encoder, decoder, val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bleu score:  25.509098833821298\n",
      "bleu score:  25.509098833821298\n",
      "bleu score:  24.771743643681983\n",
      "bleu score:  24.771743643681983\n"
     ]
    }
   ],
   "source": [
    "output_words, input_words, target_words, score= evaluate2(encoder, decoder, val_loader)\n",
    "output_words, input_words, target_words, score= evaluate2(encoder, decoder, test_loader)\n",
    "#output_words, input_words, target_words, score= evaluate2(encoder, decoder, train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_words, input_words, target_words, score= evaluate2(encoder, decoder, val_loader)\n",
    "output_words, input_words, target_words, score= evaluate2(encoder, decoder, test_loader)\n",
    "#output_words, input_words, target_words, score= evaluate2(encoder, decoder, train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(output_words)):\n",
    "    print('input: ', input_words[i])\n",
    "    print('target: ', target_words[i])\n",
    "    print('predict: ', output_words[i])\n",
    "    print('-----------------------------------------------')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sentence:\n",
    "    def __init__(self, decoder_hidden, last_idx=SOS_idx, sentence_idxes=[], sentence_scores=[]):\n",
    "        if(len(sentence_idxes) != len(sentence_scores)):\n",
    "            raise ValueError(\"length of indexes and scores should be the same\")\n",
    "        self.decoder_hidden = decoder_hidden\n",
    "        self.last_idx = last_idx\n",
    "        self.sentence_idxes =  sentence_idxes\n",
    "        self.sentence_scores = sentence_scores\n",
    "\n",
    "    def avgScore(self):\n",
    "        if len(self.sentence_scores) == 0:\n",
    "            return -100000\n",
    "            #raise ValueError(\"Calculate average score of sentence, but got no word\")\n",
    "        # return mean of sentence_score\n",
    "        return sum(self.sentence_scores) / len(self.sentence_scores)\n",
    "\n",
    "    def addTopk(self, topi, topv, decoder_hidden, beam_size):\n",
    "        #topv = torch.log(topv)\n",
    "        terminates, sentences = [], []\n",
    "        for i in range(beam_size):\n",
    "            if topi[0][i] == EOS_idx:\n",
    "                terminates.append(([en_id2token[idx.item()] for idx in self.sentence_idxes] + ['<EOS>'],\n",
    "                                   self.avgScore())) # tuple(word_list, score_float\n",
    "                continue\n",
    "            idxes = self.sentence_idxes[:] # pass by value\n",
    "            scores = self.sentence_scores[:] # pass by value\n",
    "            idxes.append(topi[0][i])\n",
    "            scores.append(topv[0][i])\n",
    "            sentences.append(Sentence(decoder_hidden, topi[0][i], idxes, scores))\n",
    "        return terminates, sentences\n",
    "\n",
    "    def toWordScore(self):\n",
    "        words = []\n",
    "        for i in range(len(self.sentence_idxes)):\n",
    "            if self.sentence_idxes[i] == EOS_idx:\n",
    "                words.append('<EOS>')\n",
    "            else:\n",
    "                words.append(en_id2token[self.sentence_idxes[i].item()])\n",
    "        if self.sentence_idxes[-1] != EOS_idx:\n",
    "            words.append('<EOS>')\n",
    "        return (words, self.avgScore())\n",
    "\n",
    "def beam_decode(decoder, decoder_hidden, encoder_outputs, beam_size, cur_batch_size, max_length=MAX_SENTENCE_LENGTH):\n",
    "    terminal_sentences, prev_top_sentences, next_top_sentences = [], [], []\n",
    "    prev_top_sentences.append(Sentence(decoder_hidden))\n",
    "    for i in range(max_length):\n",
    "        for sentence in prev_top_sentences:\n",
    "            decoder_input = torch.tensor(np.array([[sentence.last_idx]]*cur_batch_size).reshape(1,cur_batch_size),device=device)\n",
    "            #decoder_input = torch.LongTensor([[sentence.last_idx]])\n",
    "            #decoder_input = decoder_input.to(device)\n",
    "            decoder_hidden = sentence.decoder_hidden\n",
    "            decoder_output, decoder_hidden, _ = decoder(\n",
    "                decoder_input, decoder_hidden, encoder_outputs\n",
    "            )\n",
    "            topv, topi = decoder_output.topk(beam_size)\n",
    "            term, top = sentence.addTopk(topi, topv, decoder_hidden, beam_size)\n",
    "            terminal_sentences.extend(term)\n",
    "            next_top_sentences.extend(top)\n",
    "\n",
    "        next_top_sentences.sort(key=lambda s: s.avgScore(), reverse=True)\n",
    "        prev_top_sentences = next_top_sentences[:beam_size]\n",
    "        next_top_sentences = []\n",
    "\n",
    "    terminal_sentences += [sentence.toWordScore() for sentence in prev_top_sentences]\n",
    "    terminal_sentences.sort(key=lambda x: x[1], reverse=True)\n",
    "    n = 1\n",
    "    return terminal_sentences[:1]\n",
    "\n",
    "def evaluate_beam(encoder, decoder, loader, beam_size, max_length=MAX_SENTENCE_LENGTH):\n",
    "    encoder.eval()\n",
    "    decoder.eval()\n",
    "    input_words = []\n",
    "    target_words = []\n",
    "    decoded_words = []\n",
    "    num_count = 0\n",
    "    for i, (source, translate) in enumerate(loader):\n",
    "        cur_batch_size = translate.size()[0]\n",
    "        with torch.no_grad():\n",
    "            encoder_hidden = encoder.init_hidden(cur_batch_size)\n",
    "            \n",
    "        for i in range(cur_batch_size):\n",
    "            input_words.append([])\n",
    "            target_words.append([])\n",
    "        \n",
    "        for i in range(cur_batch_size):\n",
    "            for ii in range(source.size()[1]):\n",
    "                if zh_id2token[source.cpu().numpy()[i,ii]] != '<PAD>':\n",
    "                    input_words[num_count].append(zh_id2token[source.cpu().numpy()[i,ii]])\n",
    "            num_count += 1\n",
    "        num_count -= cur_batch_size\n",
    "        for i in range(cur_batch_size):\n",
    "            for ii in range(translate.size()[1]):\n",
    "                if en_id2token[translate.cpu().numpy()[i,ii]] != '<PAD>':\n",
    "                    target_words[num_count].append(en_id2token[translate.cpu().numpy()[i,ii]])\n",
    "            num_count += 1\n",
    "        \n",
    "        encoder_outputs, encoder_hidden = encoder(source, encoder_hidden)\n",
    "        \n",
    "        decoder_hidden = encoder_hidden\n",
    "        \n",
    "        decoded_words.append(beam_decode(decoder, decoder_hidden, encoder_outputs, beam_size, cur_batch_size))\n",
    "        \n",
    "    pre_list = []\n",
    "    for i in range(len(decoded_words)):\n",
    "        pre_list.append(\"\".join([\" \"+ i if not i.startswith(\"'\") and i not in string.punctuation else i for i in decoded_words[i][0][0]]).strip())\n",
    "    \n",
    "    true_list = []\n",
    "    for true_sentenc in target_words:\n",
    "        true_list.append(\"\".join([\" \"+i if not i.startswith(\"'\") and i not in string.punctuation else i for i in true_sentenc]).strip())\n",
    "    \n",
    "    score = sacrebleu.corpus_bleu(pre_list, [true_list])\n",
    "    print('bleu score: ', score.score)\n",
    "    \n",
    "    return decoded_words, target_words, score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bleu score:  25.798273814393966\n",
      "bleu score:  25.798273814393966\n"
     ]
    }
   ],
   "source": [
    "val_dataset2 = LanguageDataset(val_zh_indicies, val_en_indicies)\n",
    "val_loader2 = torch.utils.data.DataLoader(dataset=val_dataset2,\n",
    "                                           batch_size=1,\n",
    "                                           collate_fn=vocab_collate_func,\n",
    "                                           shuffle=False)\n",
    "test_dataset2 = LanguageDataset(test_zh_indicies, test_en_indicies)\n",
    "test_loader2 = torch.utils.data.DataLoader(dataset=test_dataset2,\n",
    "                                           batch_size=1,\n",
    "                                           collate_fn=vocab_collate_func,\n",
    "                                           shuffle=False)\n",
    "decoded_words1 = evaluate_beam(encoder, decoder, test_loader2, beam_size=2, max_length=MAX_SENTENCE_LENGTH)\n",
    "#output_words, input_words, target_words, score= evaluate2(encoder, decoder, val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del decoded_words1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoded_words2 = evaluate_beam(encoder, decoder, test_loader2, beam_size=3, max_length=MAX_SENTENCE_LENGTH)\n",
    "# output_words, input_words, target_words, score= evaluate2(encoder, decoder, val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
