{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import unicode_literals, print_function, division\n",
    "from io import open\n",
    "import unicodedata\n",
    "import string\n",
    "import re\n",
    "import random\n",
    "import numpy as np\n",
    "import pdb\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import io\n",
    "import os\n",
    "import sacrebleu\n",
    "from sacrebleu import raw_corpus_bleu, corpus_bleu\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "PAD_idx = 0\n",
    "SOS_idx = 1\n",
    "EOS_idx = 2\n",
    "UNK_idx= 3\n",
    "batch_size = 64\n",
    "MAX_SENTENCE_LENGTH = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class language(object):\n",
    "    def __init__(self, name, i2t, t2i, embedding_matrix, train, test, val):\n",
    "        self.name = name\n",
    "        self.idx2token = i2t\n",
    "        self.token2idx = t2i\n",
    "        self.embedding_mat = embedding_matrix\n",
    "        self.train_idx = train\n",
    "        self.test_idx = test\n",
    "        self.val_idx = val\n",
    "        \n",
    "# dataset = pickle.load(open(\"../data/zh1.1w-en6k.p\", 'rb'))\n",
    "dataset = pickle.load(open(\"../data/vi1.1w-en6k.p\", 'rb'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LanguageDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Class that represents a train/validation/test dataset that's readable for PyTorch\n",
    "    Note that this class inherits torch.utils.data.Dataset\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, source_lan, translate_lan):\n",
    "        \"\"\"\n",
    "        @param data_list: list of character\n",
    "        @param target_list: list of targets\n",
    "\n",
    "        \"\"\"\n",
    "        self.source_lan = source_lan\n",
    "        self.translate_lan = translate_lan\n",
    "        \n",
    "        assert (len(self.source_lan) == len(self.translate_lan))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.source_lan)\n",
    "\n",
    "    def __getitem__(self, key):\n",
    "        \"\"\"\n",
    "        Triggered when you call dataset[i]\n",
    "        \"\"\"\n",
    "        source_lan_idx = self.source_lan[key][:MAX_SENTENCE_LENGTH-1]\n",
    "        translation_lan_idx = self.translate_lan[key][:MAX_SENTENCE_LENGTH-1]\n",
    "        source_lan_idx.append(EOS_idx)\n",
    "        translation_lan_idx.append(EOS_idx)\n",
    "        \n",
    "        return [source_lan_idx, translation_lan_idx, len(source_lan_idx), len(translation_lan_idx)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vocab_collate_func(batch):\n",
    "    \"\"\"\n",
    "    Customized function for DataLoader that dynamically pads the batch so that all\n",
    "    data have the same length\n",
    "    \"\"\"\n",
    "    source_list = []\n",
    "    translate_list = []\n",
    "    length_list = []\n",
    "    \n",
    "    # padding\n",
    "    for datum in batch:\n",
    "\n",
    "        length_list.append(datum[2])\n",
    "        s_padded_vec = np.pad(np.array(datum[0]),\n",
    "                                pad_width=((0,MAX_SENTENCE_LENGTH-datum[2])),\n",
    "                                mode=\"constant\", constant_values=PAD_idx)\n",
    "        source_list.append(s_padded_vec)\n",
    "        t_padded_vec = np.pad(np.array(datum[1]),\n",
    "                                pad_width=((0,MAX_SENTENCE_LENGTH-datum[3])),\n",
    "                                mode=\"constant\", constant_values=PAD_idx)\n",
    "        translate_list.append(t_padded_vec)\n",
    "        \n",
    "#     ind_dec_order = np.argsort(length_list)[::-1]\n",
    "#     source_list = np.array(source_list)[ind_dec_order]\n",
    "#     length_list = np.array(length_list)[ind_dec_order]\n",
    "#     translate_list = np.array(translate_list)[ind_dec_order]\n",
    "    \n",
    "    if torch.cuda.is_available and torch.has_cudnn:\n",
    "        return [torch.from_numpy(np.array(source_list)).cuda(),torch.from_numpy(np.array(translate_list)).cuda()]\n",
    "    else:\n",
    "        return [torch.from_numpy(np.array(source_list)),torch.from_numpy(np.array(translate_list))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = LanguageDataset(dataset['src'].train_idx, dataset['tgt'].train_idx)\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
    "                                           batch_size=batch_size,\n",
    "                                           collate_fn=vocab_collate_func,\n",
    "                                           shuffle=True)\n",
    "\n",
    "val_dataset = LanguageDataset(dataset['src'].val_idx, dataset['tgt'].val_idx)\n",
    "val_loader = torch.utils.data.DataLoader(dataset=val_dataset,\n",
    "                                           batch_size=batch_size,\n",
    "                                           collate_fn=vocab_collate_func,\n",
    "                                           shuffle=False)\n",
    "\n",
    "test_dataset = LanguageDataset(dataset['src'].test_idx, dataset['tgt'].test_idx)\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset,\n",
    "                                           batch_size=batch_size,\n",
    "                                           collate_fn=vocab_collate_func,\n",
    "                                           shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DotProductAttention(nn.Module):\n",
    "    def __init__(self, sqrt_dim, attn_dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.sqrt_dim = sqrt_dim\n",
    "        self.dropout = nn.Dropout(attn_dropout)\n",
    "        self.softmax = nn.Softmax(dim=2)\n",
    "\n",
    "    def forward(self, query, k, v, mask=None):\n",
    "#         Dot product in batch\n",
    "        attn = torch.bmm(query, k.transpose(1, 2))\n",
    "#         Rescaling\n",
    "        attn = attn / self.sqrt_dim  #scale to make sure the gradient could be sufficiently bp\n",
    "#         Masking\n",
    "        if mask is not None:\n",
    "            attn = attn.masked_fill(mask, -np.inf)\n",
    "#         Normalize attention\n",
    "        attn = self.softmax(attn)\n",
    "# ------------ Notice dropout was added -------------\n",
    "        attn = self.dropout(attn)\n",
    "    \n",
    "        output = torch.bmm(attn, v)\n",
    "\n",
    "        return output, attn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class EncoderCNN(nn.Module):\n",
    "#     def __init__(self, emb_dim, hid_dim=64):\n",
    "#         super(EncoderCNN, self).__init__()\n",
    "# #         self.hid_dim = hid_dim\n",
    "#         self.embedding = nn.Embedding.from_pretrained(torch.from_numpy(dataset['src'].embedding_mat), freeze=False)\n",
    "#         self.dropout = nn.Dropout(p=0.5)\n",
    "# #         self.gru = nn.GRU(emb_dim, hid_dim, batch_first=True, bidirectional=True)\n",
    "#         self.conv1 = nn.Conv1d(emb_dim, 8*hid_dim, 7, 1, padding=3)\n",
    "#         self.bn1   = nn.BatchNorm1d(8*hid_dim)\n",
    "#         self.conv2 = nn.Conv1d(8*hid_dim, 8*hid_dim, 7, 1, padding=3)\n",
    "#         self.bn2   = nn.BatchNorm1d(8*hid_dim)\n",
    "#         self.conv3 = nn.Conv1d(8*hid_dim, 8*hid_dim, 7, 2, padding=3)\n",
    "#         self.bn3   = nn.BatchNorm1d(8*hid_dim)\n",
    "#         self.conv4 = nn.Conv1d(8*hid_dim, 8*hid_dim, 7, 1, padding=3)\n",
    "#         self.bn4   = nn.BatchNorm1d(8*hid_dim)\n",
    "#         self.conv5 = nn.Conv1d(8*hid_dim, 8*hid_dim, 7, 1, padding=3)\n",
    "#         self.bn5   = nn.BatchNorm1d(8*hid_dim)\n",
    "        \n",
    "\n",
    "#     def forward(self, inputs):\n",
    "#         encode_batch_size, length = inputs.size()\n",
    "#         embedded = self.dropout(self.embedding(inputs).float()) # the size -1 is inferred from other dimensions\n",
    "# #         pdb.set_trace()\n",
    "#         embedded = embedded.transpose(2,1)\n",
    "#         low_out = self.bn1(F.relu(self.conv1(embedded)))\n",
    "#         hidden = self.bn2(F.relu(self.conv2(low_out))+low_out)\n",
    "#         hidden = self.bn3(F.relu(self.conv3(hidden)))\n",
    "#         hidden = self.bn4(F.relu(self.conv4(hidden))+hidden)\n",
    "#         hidden = self.bn5(self.conv5(hidden)+hidden)\n",
    "#         hidden = torch.mean(hidden, dim=-1, keepdim=True)\n",
    "# #         pdb.set_trace()\n",
    "#         return low_out.transpose(2,1), hidden.permute(2,0,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderCNN(nn.Module):\n",
    "    def __init__(self, emb_dim, hid_dim=64):\n",
    "        super(EncoderCNN, self).__init__()\n",
    "        self.embedding = nn.Embedding.from_pretrained(torch.from_numpy(dataset['src'].embedding_mat), freeze=False)\n",
    "        self.dropout = nn.Dropout(p=0.5)\n",
    "#         self.conv_pre = nn.Conv1d(emb_dim, 2*hid_dim, 7, 1, padding=3)\n",
    "        self.conv1 = nn.Conv1d(emb_dim, 2*hid_dim, 7, 1, padding=3)\n",
    "        self.conv2 = nn.Conv1d(2*hid_dim, 2*hid_dim, 5, 2, padding=2)\n",
    "        self.conv3 = nn.Conv1d(2*hid_dim, 2*hid_dim, 3, 2, padding=0)\n",
    "        self.conv4 = nn.Conv1d(2*hid_dim, 2*hid_dim, 4, 2, padding=0)\n",
    "        self.conv5 = nn.Conv1d(2*hid_dim, 2*hid_dim, 5, 1, padding=0)\n",
    "        \n",
    "\n",
    "    def forward(self, inputs):\n",
    "        encode_batch_size, length = inputs.size()\n",
    "        embedded = self.dropout(self.embedding(inputs).float())\n",
    "        embedded = embedded.transpose(2,1)\n",
    "        low_out = self.dropout(F.relu(self.conv1(embedded)))\n",
    "        hidden = self.dropout(F.relu(self.conv2(low_out)))\n",
    "        hidden = self.dropout(F.relu(self.conv3(hidden)))\n",
    "        hidden = self.dropout(F.relu(self.conv4(hidden)))\n",
    "        hidden = self.conv5(hidden) \n",
    "        return low_out.transpose(2,1), hidden.permute(2,0,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderRNN(nn.Module):\n",
    "    def __init__(self, emb_dim, hid_dim, output_dim, dropout_rate=0.3):\n",
    "        super(DecoderRNN, self).__init__()\n",
    "        self.emb_dim = emb_dim\n",
    "        self.hid_dim = hid_dim\n",
    "        self.output_dim = output_dim\n",
    "        \n",
    "        self.dropout = nn.Dropout(p=dropout_rate)\n",
    "        \n",
    "        self.embedding = nn.Embedding.from_pretrained(torch.from_numpy(dataset['tgt'].embedding_mat), freeze=False)\n",
    "        \n",
    "        self.mapping = nn.Linear(self.emb_dim+self.hid_dim, self.hid_dim)\n",
    "#         self.attn_combine = nn.Linear(self.hid_dim + self.emb_dim, self.emb_dim)\n",
    "        self.dot_product_att = DotProductAttention(sqrt_dim=emb_dim)\n",
    "        \n",
    "        self.gru = nn.GRU(emb_dim+hid_dim, hid_dim)\n",
    "        self.out = nn.Linear(hid_dim, output_dim)\n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "\n",
    "    def forward(self, inputs, hidden, encoder_outputs):\n",
    "        \n",
    "        emb = self.dropout(self.embedding(inputs).float())\n",
    "        \n",
    "        attn_keys = self.mapping(torch.cat((emb, hidden), dim=2))\n",
    "        \n",
    "#         attn_applied = torch.bmm(attn_weights.unsqueeze(1), encoder_outputs)\n",
    "        \n",
    "        output, attention = self.dot_product_att(attn_keys[0].unsqueeze(0).transpose(0,1), encoder_outputs, encoder_outputs)\n",
    "\n",
    "#         output = torch.cat((emb[0], attn_applied.squeeze(1)), 1)\n",
    "#         output = self.attn_combine(output).unsqueeze(0)\n",
    "#         output = F.relu(output)\n",
    "        \n",
    "#         pdb.set_trace()\n",
    "        output, hidden = self.gru(torch.cat((emb, output.transpose(0,1)), dim=2), hidden)\n",
    "        output = self.softmax(self.out(output[0]))\n",
    "        \n",
    "        return output, hidden, attention\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "teacher_forcing_ratio = 1\n",
    "#input_tensor: list of sentence tensor\n",
    "def train(source, translate, encoder, decoder, encoder_optimizer, decoder_optimizer,\n",
    "          criterion):\n",
    "    encoder.train()\n",
    "    decoder.train()\n",
    "    \n",
    "    cur_batch_size, input_length = source.size()\n",
    "    cur_batch_size, target_length = translate.size()\n",
    "    \n",
    "    \n",
    "#     encoder_hidden = encoder.init_hidden(cur_batch_size)\n",
    "\n",
    "    encoder_optimizer.zero_grad()\n",
    "    decoder_optimizer.zero_grad()\n",
    "\n",
    "    loss = 0\n",
    "\n",
    "    encoder_output, encoder_hidden = encoder(source)\n",
    "\n",
    "    decoder_input = torch.tensor(np.array([[SOS_idx]]*cur_batch_size).reshape(1,cur_batch_size),device=device)\n",
    "    decoder_hidden = encoder_hidden\n",
    "\n",
    "    use_teacher_forcing = True if random.random() < teacher_forcing_ratio else False\n",
    "    if use_teacher_forcing:\n",
    "        # Teacher forcing: Feed the target as the next input\n",
    "        for i in range(target_length):\n",
    "        \n",
    "            decoder_output, decoder_hidden, decoder_attention = decoder(decoder_input, decoder_hidden, encoder_output)\n",
    "            \n",
    "            loss += criterion(decoder_output, translate[:,i])\n",
    "            decoder_input = translate[:,i].unsqueeze(0)  # Teacher forcing\n",
    "            \n",
    "    else:\n",
    "        # Without teacher forcing: use its own predictions as the next input\n",
    "        for i in range(target_length):\n",
    "            decoder_output, decoder_hidden, decoder_attention= decoder(decoder_input, decoder_hidden, encoder_output)\n",
    "            topv, topi = decoder_output.topk(1)\n",
    "            decoder_input = topi.squeeze().detach()  # detach from history as input\n",
    "            \n",
    "            #decoder_input [1, batch size] \n",
    "            decoder_input = decoder_input.unsqueeze(0)\n",
    " \n",
    "            loss += criterion(decoder_output, translate[:,i])\n",
    "\n",
    "    loss.backward()\n",
    "\n",
    "    encoder_optimizer.step()\n",
    "    decoder_optimizer.step()\n",
    "\n",
    "    return loss.item() / target_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_corpus_bleu(output_words, target_words):\n",
    "    output_sentence = [' '.join(parser(words)) for words in output_words]\n",
    "    target_sentence = [' '.join(parser(words)) for words in target_words]\n",
    "    \n",
    "#     ref_sent_list = [[i.split()] for i in target_sentence]\n",
    "#     candidate_sent_list = [i.split() for i in output_sentence]\n",
    "    ref_sent_list = [[i for i in target_sentence]]\n",
    "    candidate_sent_list = [i for i in output_sentence]\n",
    "#     pdb.set_trace()\n",
    "#     score = corpus_bleu(ref_sent_list, candidate_sent_list, smoothing_function=chencherry.method1)\n",
    "    score = raw_corpus_bleu(candidate_sent_list, ref_sent_list)\n",
    "    \n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate2(encoder, decoder, loader):\n",
    "    encoder.eval()\n",
    "    decoder.eval()\n",
    "    input_words = []\n",
    "    target_words = []\n",
    "    decoded_words = []\n",
    "    num_count = 0\n",
    "    num_count = 0\n",
    "    for i, (source, translate) in enumerate(loader):\n",
    "        \n",
    "        if i > 20:\n",
    "            break\n",
    "        \n",
    "        cur_batch_size = translate.size()[0]\n",
    "            \n",
    "#         with torch.no_grad():\n",
    "#             encoder_hidden = encoder.init_hidden(cur_batch_size)\n",
    "        \n",
    "        input_tensor = source\n",
    "        target_tensor = translate\n",
    "        target_length = target_tensor.size()[1]\n",
    "        \n",
    "        encoder_output, encoder_hidden = encoder(input_tensor)\n",
    "\n",
    "        decoder_input = torch.tensor(np.array([[SOS_idx]]*cur_batch_size).reshape(1,cur_batch_size),device=device)\n",
    "        decoder_hidden = encoder_hidden\n",
    "        \n",
    "        for i in range(cur_batch_size):\n",
    "            decoded_words.append([])\n",
    "            input_words.append([])\n",
    "            target_words.append([])\n",
    "        \n",
    "        for i in range(cur_batch_size):\n",
    "            for ii in range(input_tensor.size()[1]):\n",
    "                if dataset['src'].idx2token[input_tensor.cpu().numpy()[i,ii]] != '<PAD>':\n",
    "                    input_words[num_count].append(dataset['src'].idx2token[input_tensor.cpu().numpy()[i,ii]])\n",
    "            num_count += 1\n",
    "        num_count -= cur_batch_size\n",
    "        for i in range(cur_batch_size):\n",
    "            for ii in range(target_tensor.size()[1]):\n",
    "                if dataset['tgt'].idx2token[target_tensor.cpu().numpy()[i,ii]] != '<PAD>':\n",
    "                    target_words[num_count].append(dataset['tgt'].idx2token[target_tensor.cpu().numpy()[i,ii]])\n",
    "            num_count += 1\n",
    "        num_count -= cur_batch_size      \n",
    "        \n",
    "        cur_len = np.zeros(cur_batch_size, dtype=int)\n",
    "        #pdb.set_trace()\n",
    "        for i in range(target_length):\n",
    "            decoder_output, decoder_hidden, decoder_attention = decoder(decoder_input, decoder_hidden, encoder_output)\n",
    "            topv, topi = decoder_output.topk(1)\n",
    "            decoder_input = topi.squeeze().detach()  # detach from history as input\n",
    "            decoder_input = decoder_input.unsqueeze(0)\n",
    "            \n",
    "            topi = topi.squeeze().cpu().numpy()\n",
    "            if cur_len[0] == 0:\n",
    "                for i in range(len(topi)):\n",
    "                    decoded_words[num_count+i].append(dataset['tgt'].idx2token[topi[i]])\n",
    "                    cur_len[i] += 1\n",
    "            \n",
    "            else:\n",
    "                for i in range(len(topi)):\n",
    "                    if decoded_words[num_count+i][cur_len[i]-1] == '<EOS>':\n",
    "                        continue\n",
    "                    decoded_words[num_count+i].append(dataset['tgt'].idx2token[topi[i]])\n",
    "                    cur_len[i] += 1\n",
    "        num_count += cur_batch_size\n",
    "    pre_list = []\n",
    "    for pre_sentenc in decoded_words:\n",
    "        pre_list.append(\"\".join([\" \"+i if not i.startswith(\"'\") and i not in string.punctuation else i for i in pre_sentenc]).strip())\n",
    "\n",
    "    true_list = []\n",
    "    for true_sentenc in target_words:\n",
    "        true_list.append(\"\".join([\" \"+i if not i.startswith(\"'\") and i not in string.punctuation else i for i in true_sentenc]).strip())\n",
    "    \n",
    "    true_list2 = []\n",
    "    true_list2.append(true_list)        \n",
    "    score = sacrebleu.corpus_bleu(pre_list, true_list2)\n",
    "    print('bleu score: ', score.score)\n",
    "    return decoded_words,input_words, target_words, score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainIters(encoder, decoder, n_iters, print_every=800, plot_every=200, learning_rate=0.001):\n",
    "    start = time.time()\n",
    "    plot_losses = []\n",
    "    print_loss_total = 0  # Reset every print_every\n",
    "    plot_loss_total = 0  # Reset every plot_every\n",
    "    \n",
    "    best_score = 0\n",
    "    best_past = 0\n",
    "    \n",
    "    encoder_optimizer = optim.Adam(encoder.parameters(), lr=learning_rate)\n",
    "    decoder_optimizer = optim.Adam(decoder.parameters(), lr=learning_rate)\n",
    "    criterion = nn.NLLLoss(ignore_index = 0)\n",
    "    count_iter = 0\n",
    "    for cur_iter in range(1, n_iters + 1):\n",
    "        for i, (source, translate) in tqdm(enumerate(train_loader) ,total=len(train_loader)):\n",
    "            \n",
    "            loss = train(source, translate, encoder,\n",
    "                         decoder, encoder_optimizer, decoder_optimizer, criterion)\n",
    "            print_loss_total += loss\n",
    "            plot_loss_total += loss\n",
    "            count_iter += 1\n",
    "            \n",
    "            if count_iter % plot_every == 0:\n",
    "                plot_loss_avg = plot_loss_total / plot_every\n",
    "                plot_losses.append(plot_loss_avg)\n",
    "                plot_loss_total = 0\n",
    "#             if count_iter % print_every == 0:\n",
    "        \n",
    "        print_loss_avg = print_loss_total / print_every\n",
    "        print_loss_total = 0\n",
    "        print('%d %d%% %.4f' % (cur_iter, cur_iter / n_iters * 100, print_loss_avg))\n",
    "\n",
    "        print('Train: ')\n",
    "        _,_,_, score = evaluate2(encoder, decoder, train_loader)\n",
    "        with open('out4.txt', 'a') as file:\n",
    "            file.write('small train: ' + str(score.score) + '\\n')\n",
    "\n",
    "        print('validation: ')\n",
    "        _,_,_, score = evaluate2(encoder, decoder, val_loader)\n",
    "        with open('out4.txt', 'a') as file:\n",
    "            file.write('validation: ' + str(score.score) + '\\n')\n",
    "            \n",
    "        if score.score > best_score:\n",
    "            best_past = 0\n",
    "            best_score = score.score\n",
    "        else:\n",
    "#             learning_rate /= 5\n",
    "#             encoder_optimizer = optim.Adam(encoder.parameters(), lr=learning_rate)\n",
    "#             decoder_optimizer = optim.Adam(decoder.parameters(), lr=learning_rate)\n",
    "            best_past += 1\n",
    "        \n",
    "            \n",
    "\n",
    "        encoder_chkpt = encoder.state_dict()\n",
    "        decoder_chkpt = decoder.state_dict()\n",
    "        chkpt = {\n",
    "            'encoder': encoder_chkpt,\n",
    "            'decoder': decoder_chkpt,\n",
    "            'epoch': cur_iter\n",
    "        }\n",
    "                \n",
    "        model_name = './chkpt/conv_att_vi'+'_accu_{accu:3.3f}.chkpt'.format(accu=score.score)\n",
    "        torch.save(chkpt, model_name)\n",
    "        \n",
    "        if best_past > 4:\n",
    "            break\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.switch_backend('agg')\n",
    "import matplotlib.ticker as ticker\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "\n",
    "def showPlot(points):\n",
    "    plt.figure()\n",
    "    fig, ax = plt.subplots()\n",
    "    # this locator puts ticks at regular intervals\n",
    "    loc = ticker.MultipleLocator(base=0.2)\n",
    "    ax.yaxis.set_major_locator(loc)\n",
    "    plt.plot(points)\n",
    "    plt.show()\n",
    "    \n",
    "import time\n",
    "import math\n",
    "\n",
    "def asMinutes(s):\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)\n",
    "\n",
    "\n",
    "def timeSince(since, percent):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    es = s / (percent)\n",
    "    rs = es - s\n",
    "    return '%s (- %s)' % (asMinutes(s), asMinutes(rs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2084/2084 [07:17<00:00,  5.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 1% 11.7820\n",
      "Train: \n",
      "bleu score:  15.061024883166462\n",
      "validation: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/2084 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bleu score:  14.484976631267727\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2084/2084 [07:14<00:00,  5.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 3% 10.2187\n",
      "Train: \n",
      "bleu score:  14.964027880293228\n",
      "validation: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/2084 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bleu score:  14.975729718783354\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2084/2084 [07:25<00:00,  5.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 5% 9.3464\n",
      "Train: \n",
      "bleu score:  15.279716279084202\n",
      "validation: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/2084 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bleu score:  15.28007109179704\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2084/2084 [07:25<00:00,  4.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 6% 8.6386\n",
      "Train: \n",
      "bleu score:  18.2834048082564\n",
      "validation: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/2084 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bleu score:  17.358035164411092\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2084/2084 [07:25<00:00,  5.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 8% 8.0855\n",
      "Train: \n",
      "bleu score:  18.815586942490448\n",
      "validation: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/2084 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bleu score:  18.62723702770037\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2084/2084 [07:23<00:00,  5.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6 10% 7.6406\n",
      "Train: \n",
      "bleu score:  20.292531304812524\n",
      "validation: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/2084 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bleu score:  18.589302181504713\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2084/2084 [07:25<00:00,  5.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7 11% 7.3054\n",
      "Train: \n",
      "bleu score:  21.568634457597483\n",
      "validation: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/2084 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bleu score:  20.856311578269317\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2084/2084 [07:25<00:00,  5.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8 13% 7.0438\n",
      "Train: \n",
      "bleu score:  21.912543629438762\n",
      "validation: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/2084 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bleu score:  20.65989065390471\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2084/2084 [07:25<00:00,  5.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9 15% 6.8221\n",
      "Train: \n",
      "bleu score:  22.218984544484336\n",
      "validation: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/2084 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bleu score:  21.199546294905456\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2084/2084 [07:24<00:00,  4.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 16% 6.6555\n",
      "Train: \n",
      "bleu score:  22.199219093573458\n",
      "validation: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/2084 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bleu score:  21.20398097970649\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2084/2084 [07:25<00:00,  5.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11 18% 6.5162\n",
      "Train: \n",
      "bleu score:  22.30245746331308\n",
      "validation: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/2084 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bleu score:  19.490866051570908\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2084/2084 [07:25<00:00,  5.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12 20% 6.4093\n",
      "Train: \n",
      "bleu score:  23.16324400766306\n",
      "validation: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/2084 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bleu score:  21.56431746643927\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2084/2084 [07:24<00:00,  5.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13 21% 6.2990\n",
      "Train: \n",
      "bleu score:  23.744560218111644\n",
      "validation: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/2084 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bleu score:  21.918387306956316\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2084/2084 [07:24<00:00,  5.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14 23% 6.2179\n",
      "Train: \n",
      "bleu score:  23.91132490913671\n",
      "validation: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/2084 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bleu score:  21.442226090034325\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2084/2084 [07:20<00:00,  5.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15 25% 6.1374\n",
      "Train: \n",
      "bleu score:  22.077023313827304\n",
      "validation: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/2084 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bleu score:  20.044509318203808\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2084/2084 [07:13<00:00,  5.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16 26% 6.0744\n",
      "Train: \n",
      "bleu score:  24.3412892091887\n",
      "validation: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/2084 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bleu score:  22.134169119469593\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2084/2084 [07:14<00:00,  5.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17 28% 6.0300\n",
      "Train: \n",
      "bleu score:  24.273377866253952\n",
      "validation: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/2084 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bleu score:  22.356843599657328\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2084/2084 [07:24<00:00,  5.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18 30% 5.9797\n",
      "Train: \n",
      "bleu score:  24.277146694191035\n",
      "validation: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/2084 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bleu score:  21.770227644617098\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2084/2084 [07:24<00:00,  5.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19 31% 5.9563\n",
      "Train: \n",
      "bleu score:  23.787021702600327\n",
      "validation: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/2084 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bleu score:  22.0688955777237\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2084/2084 [07:23<00:00,  5.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20 33% 5.9348\n",
      "Train: \n",
      "bleu score:  24.319494072904437\n",
      "validation: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/2084 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bleu score:  22.257669722422996\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2084/2084 [07:25<00:00,  5.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21 35% 5.8758\n",
      "Train: \n",
      "bleu score:  24.823406367177814\n",
      "validation: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/2084 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bleu score:  22.46881395788667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2084/2084 [07:24<00:00,  5.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22 36% 5.8500\n",
      "Train: \n",
      "bleu score:  24.722329598745947\n",
      "validation: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/2084 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bleu score:  21.673493508130996\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2084/2084 [07:13<00:00,  5.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23 38% 5.9140\n",
      "Train: \n",
      "bleu score:  23.841404071880856\n",
      "validation: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/2084 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bleu score:  22.79512083834368\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2084/2084 [07:12<00:00,  5.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24 40% 5.8190\n",
      "Train: \n",
      "bleu score:  25.09616921951\n",
      "validation: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/2084 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bleu score:  22.682886286549852\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 293/2084 [01:02<06:42,  4.45it/s]"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-ee163446134e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;31m# print ('success in loading from pretrained')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m \u001b[0mtrainIters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m60\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-14-e427038be92c>\u001b[0m in \u001b[0;36mtrainIters\u001b[0;34m(encoder, decoder, n_iters, print_every, plot_every, learning_rate)\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m             loss = train(source, translate, encoder,\n\u001b[0;32m---> 18\u001b[0;31m                          decoder, encoder_optimizer, decoder_optimizer, criterion)\n\u001b[0m\u001b[1;32m     19\u001b[0m             \u001b[0mprint_loss_total\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m             \u001b[0mplot_loss_total\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-11-818713aaf509>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(source, translate, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion)\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget_length\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m             \u001b[0mdecoder_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder_hidden\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder_attention\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdecoder_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder_hidden\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoder_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdecoder_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtranslate\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    475\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    476\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 477\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    478\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    479\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-10-dbc2e5ac589a>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, inputs, hidden, encoder_outputs)\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;31m#         pdb.set_trace()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m         \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgru\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0memb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    475\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    476\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 477\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    478\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    479\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    190\u001b[0m             \u001b[0mflat_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mflat_weight\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    191\u001b[0m         )\n\u001b[0;32m--> 192\u001b[0;31m         \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall_weights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    193\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_packed\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPackedSequence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/nn/_functions/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(input, *fargs, **fkwargs)\u001b[0m\n\u001b[1;32m    322\u001b[0m             \u001b[0mfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecorator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 324\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mfargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    325\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    326\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/nn/_functions/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(input, weight, hx, batch_sizes)\u001b[0m\n\u001b[1;32m    286\u001b[0m             \u001b[0mbatch_first\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdropout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbidirectional\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    287\u001b[0m             \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_sizes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mvariable_length\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 288\u001b[0;31m             dropout_ts)\n\u001b[0m\u001b[1;32m    289\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    290\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcx\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "ENC_EMB_DIM = 300\n",
    "VI_EMB_DIM = 300\n",
    "CONV_HID_DIM = 256\n",
    "HID_DIM = 256\n",
    "OUTPUT_DIM = len(dataset['tgt'].token2idx)\n",
    "\n",
    "\n",
    "encoder = EncoderCNN(ENC_EMB_DIM, CONV_HID_DIM).to(device)\n",
    "decoder = DecoderRNN(VI_EMB_DIM, HID_DIM*2, OUTPUT_DIM).to(device)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# chkpt = torch.load(\"./chkpt/conv_att_ch_accu_1.517.chkpt\")\n",
    "\n",
    "# encoder.load_state_dict(chkpt['encoder'])\n",
    "# decoder.load_state_dict(chkpt['decoder'])\n",
    "\n",
    "# print ('success in loading from pretrained')\n",
    "\n",
    "trainIters(encoder, decoder, 60)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate best ch-en model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "success in loading from pretrained\n",
      "bleu score:  20.56176219575077\n"
     ]
    }
   ],
   "source": [
    "chkpt = torch.load(\"./chkpt/conv_att_ch_accu_18.380.chkpt\")\n",
    "dataset = pickle.load(open(\"../data/zh1.1w-en6k.p\", 'rb'))\n",
    "encoder.load_state_dict(chkpt['encoder'])\n",
    "decoder.load_state_dict(chkpt['decoder'])\n",
    "\n",
    "print ('success in loading from pretrained')\n",
    "_ = evaluate2(encoder, decoder, test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate the best VI-EN model\n",
    "- noticed the validation score from the name is smaller since it was evaluated with raw score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "success in loading from pretrained\n",
      "bleu score:  23.817502880117285\n"
     ]
    }
   ],
   "source": [
    "dataset = pickle.load(open(\"../data/vi1.1w-en6k.p\", 'rb'))\n",
    "\n",
    "chkpt = torch.load(\"./chkpt/conv_att_vi_accu_22.795.chkpt\")\n",
    "\n",
    "encoder.load_state_dict(chkpt['encoder'])\n",
    "decoder.load_state_dict(chkpt['decoder'])\n",
    "\n",
    "print ('success in loading from pretrained')\n",
    "_ = evaluate2(encoder, decoder, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
